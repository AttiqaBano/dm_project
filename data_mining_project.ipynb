{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Io6rKhWkyGlB",
        "outputId": "baa502e1-0c36-4b58-a031-cf6167737533"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDependencies installed successfully\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install -q transformers sentence-transformers spacy bertopic plotly pandas numpy scikit-learn nltk umap-learn hdbscan gensim tqdm scipy\n",
        "\n",
        "print(\"Dependencies installed successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "!pip install vaderSentiment\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from scipy.stats import ttest_1samp, ttest_ind, ttest_rel, f_oneway, chi2_contingency\n",
        "import warnings\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "from datetime import datetime\n",
        "from collections import Counter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iU8AFS-RTb3N",
        "outputId": "56668745-13f0-4084-90c3-69a68c886bf2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from vaderSentiment) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->vaderSentiment) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->vaderSentiment) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->vaderSentiment) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->vaderSentiment) (2025.11.12)\n",
            "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/126.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Machine Learning imports\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation, PCA\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, accuracy_score,\n",
        "    f1_score, precision_score, recall_score, roc_auc_score,\n",
        "    silhouette_score, calinski_harabasz_score\n",
        ")\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import joblib\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "_52H1n7_daev"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1CY8VVM280M",
        "outputId": "cc8fb43c-8af5-4f5a-a183-353897fb75da"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "class Config:\n",
        "    # File paths\n",
        "    DATA_FILES = {\n",
        "        'dawn': \"/content/drive/MyDrive/dawn.csv\",\n",
        "        'daily_times': \"/content/drive/MyDrive/daily_times(full-data).csv\",\n",
        "    }\n",
        "\n",
        "    # Output directories\n",
        "    OUTPUT_DIR = \"outputs\"\n",
        "    MODELS_DIR = \"models\"\n",
        "    REPORTS_DIR = \"reports\"\n",
        "\n",
        "    # Preprocessing settings (matching original)\n",
        "    TEXT_COLUMNS = ['headline', 'description']\n",
        "    CATEGORY_MAPPING = {\n",
        "        'sport': 'Sports',\n",
        "        'pakistan': 'Pakistan',\n",
        "        'world': 'International',\n",
        "        'politic': 'Politics',\n",
        "        'default': 'Miscellaneous'\n",
        "    }\n",
        "\n",
        "    # Model settings\n",
        "    TEST_SIZE = 0.2\n",
        "    RANDOM_STATE = 42\n",
        "    N_CLUSTERS = 5\n",
        "\n",
        "    # Visualization settings\n",
        "    PLOT_STYLE = 'whitegrid'\n",
        "    COLOR_PALETTE = 'viridis'\n",
        "\n",
        "# Create directories\n",
        "for dir_path in [Config.OUTPUT_DIR, Config.MODELS_DIR, Config.REPORTS_DIR]:\n",
        "    os.makedirs(dir_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "ellyMUT7ds3a"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loading\n",
        "\n",
        "print(\"Phase 01: Data Loading & Integration\")\n",
        "\n",
        "def load_csv_safe(file_path):\n",
        "    \"\"\"\n",
        "    Safely loads a CSV file, trying both 'utf-8' and 'latin1' encodings.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return pd.read_csv(\n",
        "            file_path,\n",
        "            encoding=\"utf-8\",\n",
        "            engine=\"python\",\n",
        "            delimiter=\",\",\n",
        "            on_bad_lines=\"skip\"\n",
        "        )\n",
        "    except UnicodeDecodeError:\n",
        "        return pd.read_csv(\n",
        "            file_path,\n",
        "            encoding=\"latin1\",\n",
        "            engine=\"python\",\n",
        "            delimiter=\",\",\n",
        "            on_bad_lines=\"skip\"\n",
        "        )\n",
        "\n",
        "def load_and_prepare_datasets():\n",
        "    \"\"\"\n",
        "    Load and prepare three datasets following original preprocessing style\n",
        "    \"\"\"\n",
        "    datasets = {}\n",
        "\n",
        "    for name, file_path in Config.DATA_FILES.items():\n",
        "        print(f\"Loading {name} from {file_path}...\")\n",
        "\n",
        "        try:\n",
        "            df = load_csv_safe(file_path)\n",
        "\n",
        "            # Remove unnamed columns (original approach)\n",
        "            df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
        "\n",
        "            # Select columns (original approach)\n",
        "            required_cols = ['headline', 'date', 'link', 'source', 'categories', 'description']\n",
        "            available_cols = [col for col in required_cols if col in df.columns]\n",
        "            df = df[available_cols]\n",
        "\n",
        "            # Add dataset identifier\n",
        "            df['dataset'] = name.capitalize().replace('_', ' ')\n",
        "\n",
        "            datasets[name] = df\n",
        "            print(f\"  ✓ Loaded {len(df)} rows, {len(df.columns)} columns\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ✗ Error loading {name}: {str(e)}\")\n",
        "            datasets[name] = pd.DataFrame()\n",
        "\n",
        "    return datasets\n",
        "\n",
        "# Load datasets\n",
        "datasets = load_and_prepare_datasets()\n",
        "\n",
        "# Combine datasets (original approach)\n",
        "dfs_to_combine = [df for df in datasets.values() if not df.empty]\n",
        "if len(dfs_to_combine) >= 2:\n",
        "    combined_df = pd.concat(dfs_to_combine, ignore_index=True)\n",
        "    print(f\"\\n✓ Combined dataset: {len(combined_df)} rows, {len(combined_df.columns)} columns\")\n",
        "else:\n",
        "    raise ValueError(\"Need at least 2 datasets to proceed\")"
      ],
      "metadata": {
        "id": "0i7sCX8aeAYA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f8a1710-1268-4264-9db0-a24df9f5737a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phase 01: Data Loading & Integration\n",
            "Loading dawn from /content/drive/MyDrive/dawn.csv...\n",
            "  ✓ Loaded 45068 rows, 7 columns\n",
            "Loading daily_times from /content/drive/MyDrive/daily_times(full-data).csv...\n",
            "  ✓ Loaded 171919 rows, 7 columns\n",
            "\n",
            "✓ Combined dataset: 216987 rows, 7 columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "\n",
        "print(\"Phase 02: Preprocessing\")\n",
        "\n",
        "\n",
        "# Step 1: Clean column names (original approach)\n",
        "combined_df.columns = combined_df.columns.str.strip().str.lower()\n",
        "print(\"✓ Column names standardized\")\n",
        "\n",
        "# Step 2: Fill missing values (original approach)\n",
        "text_columns = ['headline', 'description']\n",
        "for col in text_columns:\n",
        "    if col in combined_df.columns:\n",
        "        combined_df[col] = combined_df[col].fillna('').astype(str)\n",
        "        print(f\"✓ {col}: Missing values filled\")\n",
        "\n",
        "if 'source' in combined_df.columns:\n",
        "    combined_df['source'] = combined_df['source'].fillna('Unknown').astype(str)\n",
        "    print(\"✓ source: Missing values filled\")\n",
        "\n",
        "if 'categories' in combined_df.columns:\n",
        "    combined_df['categories'] = combined_df['categories'].fillna('miscellaneous').astype(str)\n",
        "    print(\"✓ categories: Missing values filled\")\n",
        "\n",
        "# Step 3: Category standardization (original mapping function)\n",
        "def map_category_original(cat):\n",
        "    \"\"\"\n",
        "    Original category mapping function from provided code\n",
        "    \"\"\"\n",
        "    cat = str(cat).strip().lower()\n",
        "\n",
        "    # Sports\n",
        "    if \"sport\" in cat:\n",
        "        return \"Sports\"\n",
        "\n",
        "    # Pakistan\n",
        "    elif \"pakistan\" in cat or cat in [\"islamabad\", \"punjab\", \"sindh\", \"balochistan\", \"khyber pakhtunkhwa\"]:\n",
        "        return \"Pakistan\"\n",
        "\n",
        "    # International\n",
        "    elif \"world\" in cat:\n",
        "        return \"International\"\n",
        "\n",
        "    # Politics\n",
        "    elif \"politic\" in cat or cat in [\"op-ed\", \"editorial\", \"commentary / insight\",\n",
        "                                    \"letters\", \"perspectives\", \"prism\", \"cartoons\"]:\n",
        "        return \"Politics\"\n",
        "\n",
        "    # Miscellaneous\n",
        "    else:\n",
        "        return \"Miscellaneous\"\n",
        "\n",
        "# Apply original mapping\n",
        "if 'categories' in combined_df.columns:\n",
        "    combined_df['major_category'] = combined_df['categories'].apply(map_category_original)\n",
        "    print(\"✓ Categories mapped using original function\")\n",
        "\n",
        "    # Show distribution\n",
        "    print(\"\\nCategory Distribution:\")\n",
        "    print(combined_df['major_category'].value_counts())\n",
        "\n",
        "# Save integrated dataset\n",
        "combined_df.to_csv(f\"{Config.OUTPUT_DIR}/integrated_datasets.csv\", index=False, encoding=\"utf-8\")\n",
        "print(f\"\\n Integrated dataset saved to {Config.OUTPUT_DIR}/Integrated_Three_Datasets.csv\")"
      ],
      "metadata": {
        "id": "hiq0pIDceSR9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d87f674-8ea2-4cb8-919f-01f604e84d4f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phase 02: Preprocessing\n",
            "✓ Column names standardized\n",
            "✓ headline: Missing values filled\n",
            "✓ description: Missing values filled\n",
            "✓ source: Missing values filled\n",
            "✓ categories: Missing values filled\n",
            "✓ Categories mapped using original function\n",
            "\n",
            "Category Distribution:\n",
            "major_category\n",
            "Pakistan         84736\n",
            "Miscellaneous    57881\n",
            "International    33191\n",
            "Sports           28589\n",
            "Politics         12590\n",
            "Name: count, dtype: int64\n",
            "\n",
            " Integrated dataset saved to outputs/Integrated_Three_Datasets.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering\n",
        "print(\"Phase 03: Feature Engineering\\n\")\n",
        "\n",
        "# Initialize VADER (original approach)\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Feature 1: Text lengths (original approach)\n",
        "if 'headline' in combined_df.columns:\n",
        "    combined_df['headline_len_words'] = combined_df['headline'].str.split().apply(len)\n",
        "    print(\"headline_len_words created\")\n",
        "\n",
        "if 'description' in combined_df.columns:\n",
        "    combined_df['description_len_words'] = combined_df['description'].str.split().apply(len)\n",
        "    print(\"description_len_words created\")\n",
        "\n",
        "# Feature 2: Sentiment scores (original VADER approach)\n",
        "def vader_compound_original(text):\n",
        "    \"\"\"Original VADER sentiment function\"\"\"\n",
        "    if not text or str(text).strip() == '':\n",
        "        return 0.0\n",
        "    return analyzer.polarity_scores(str(text))['compound']\n",
        "\n",
        "if 'headline' in combined_df.columns:\n",
        "    combined_df['headline_sentiment_score'] = combined_df['headline'].apply(vader_compound_original)\n",
        "    print(\"headline_sentiment_score created\")\n",
        "\n",
        "if 'description' in combined_df.columns:\n",
        "    combined_df['description_sentiment_score'] = combined_df['description'].apply(vader_compound_original)\n",
        "    print(\"description_sentiment_score created\")\n",
        "\n",
        "# Feature 3: Sentiment labels (original thresholds)\n",
        "def sentiment_label_original(compound):\n",
        "    \"\"\"Original sentiment labeling function\"\"\"\n",
        "    if compound >= 0.05:\n",
        "        return 'positive'\n",
        "    if compound <= -0.05:\n",
        "        return 'negative'\n",
        "    return 'neutral'\n",
        "\n",
        "if 'headline_sentiment_score' in combined_df.columns:\n",
        "    combined_df['headline_sentiment_label'] = combined_df['headline_sentiment_score'].apply(sentiment_label_original)\n",
        "    print(\"headline_sentiment_label created\")\n",
        "\n",
        "if 'description_sentiment_score' in combined_df.columns:\n",
        "    combined_df['description_sentiment_label'] = combined_df['description_sentiment_score'].apply(sentiment_label_original)\n",
        "    print(\"description_sentiment_label created\")"
      ],
      "metadata": {
        "id": "p1m2TEiLekb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72ee33f0-f154-467e-d44c-3bf8858155b1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phase 03: Feature Engineering\n",
            "\n",
            "headline_len_words created\n",
            "description_len_words created\n",
            "headline_sentiment_score created\n",
            "description_sentiment_score created\n",
            "headline_sentiment_label created\n",
            "description_sentiment_label created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploratory Data Analysis\n",
        "print(\"Phase 04: Exploratory Data Analysis\\n\")\n",
        "\n",
        "# Set style (original approach)\n",
        "sns.set(style=Config.PLOT_STYLE, font_scale=1.0)\n",
        "\n",
        "# 1. Summary statistics\n",
        "def summary_stats_original(series):\n",
        "    \"\"\"Original summary statistics function\"\"\"\n",
        "    s = series.dropna()\n",
        "    return {\n",
        "        'count': int(s.count()),\n",
        "        'mean': float(s.mean()),\n",
        "        'median': float(s.median()),\n",
        "        'mode': s.mode().iloc[0] if not s.mode().empty else np.nan,\n",
        "        'variance': float(s.var(ddof=0)),   # population variance\n",
        "        'std': float(s.std(ddof=0)),\n",
        "        'skewness': float(s.skew())\n",
        "    }\n",
        "\n",
        "# Compute statistics for key columns\n",
        "stats_columns = ['headline_len_words', 'description_len_words',\n",
        "                 'headline_sentiment_score', 'description_sentiment_score']\n",
        "stats_dict = {}\n",
        "\n",
        "for col in stats_columns:\n",
        "    if col in combined_df.columns:\n",
        "        stats_dict[col] = summary_stats_original(combined_df[col])\n",
        "\n",
        "# Save statistics\n",
        "if stats_dict:\n",
        "    stats_df = pd.DataFrame(stats_dict).T\n",
        "    stats_df.to_csv(f\"{Config.OUTPUT_DIR}/summary_statistics_original.csv\")\n",
        "    print(\"Summary statistics saved\")\n",
        "\n",
        "# 2. Outlier detection\n",
        "def iqr_outliers_original(series):\n",
        "    \"\"\"Original IQR outlier detection\"\"\"\n",
        "    q1 = series.quantile(0.25)\n",
        "    q3 = series.quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    lower = q1 - 1.5 * iqr\n",
        "    upper = q3 + 1.5 * iqr\n",
        "    return (series < lower) | (series > upper)\n",
        "\n",
        "# Apply outlier detection\n",
        "if 'headline_len_words' in combined_df.columns:\n",
        "    combined_df['headline_len_outlier'] = iqr_outliers_original(combined_df['headline_len_words'])\n",
        "\n",
        "if 'description_len_words' in combined_df.columns:\n",
        "    combined_df['description_len_outlier'] = iqr_outliers_original(combined_df['description_len_words'])\n",
        "\n",
        "# Extreme sentiment (original threshold)\n",
        "if 'headline_sentiment_score' in combined_df.columns:\n",
        "    combined_df['headline_extreme_sentiment'] = combined_df['headline_sentiment_score'].abs() >= 0.8\n",
        "\n",
        "print(\"Outlier detection completed\")\n",
        "\n",
        "# 3. Group statistics (original approach)\n",
        "if 'source' in combined_df.columns and 'headline_sentiment_score' in combined_df.columns:\n",
        "    avg_sent_by_source = combined_df.groupby('source')['headline_sentiment_score'].agg(['count', 'mean', 'std']).sort_values('mean', ascending=False)\n",
        "    avg_sent_by_source.to_csv(f\"{Config.OUTPUT_DIR}/avg_sentiment_by_source_original.csv\")\n",
        "    print(\"Source sentiment analysis saved\")\n",
        "\n",
        "if 'major_category' in combined_df.columns and 'headline_sentiment_score' in combined_df.columns:\n",
        "    avg_sent_by_category = combined_df.groupby('major_category')['headline_sentiment_score'].agg(['count', 'mean', 'std']).sort_values('mean', ascending=False)\n",
        "    avg_sent_by_category.to_csv(f\"{Config.OUTPUT_DIR}/avg_sentiment_by_category_original.csv\")\n",
        "    print(\"Category sentiment analysis saved\")"
      ],
      "metadata": {
        "id": "vFRWkFjefM1n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc18a3e5-13bf-43b6-ca84-432798de2550"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phase 04: Exploratory Data Analysis\n",
            "\n",
            "Summary statistics saved\n",
            "Outlier detection completed\n",
            "Source sentiment analysis saved\n",
            "Category sentiment analysis saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizations\n",
        "print(\"Phase 05 Visualizations\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 1. Length distributions\n",
        "if 'headline_len_words' in combined_df.columns:\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.hist(combined_df['headline_len_words'], bins=50, color='skyblue', edgecolor='black')\n",
        "    plt.title(\"Headline Length Distribution (Original)\")\n",
        "    plt.xlabel(\"Words in headline\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.savefig(f\"{Config.OUTPUT_DIR}/headline_length_hist_original.png\", bbox_inches=\"tight\", dpi=300)\n",
        "    plt.close()\n",
        "    print(\"Headline length histogram saved\")\n",
        "\n",
        "if 'description_len_words' in combined_df.columns:\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.hist(combined_df['description_len_words'], bins=60, color='lightgreen', edgecolor='black')\n",
        "    plt.title(\"Description Length Distribution (Original)\")\n",
        "    plt.xlabel(\"Words in description\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.savefig(f\"{Config.OUTPUT_DIR}/description_length_hist_original.png\", bbox_inches=\"tight\", dpi=300)\n",
        "    plt.close()\n",
        "    print(\"\\n Description length histogram saved\")\n",
        "\n",
        "# 2. Word clouds\n",
        "if 'headline' in combined_df.columns and 'headline_sentiment_label' in combined_df.columns:\n",
        "    # Positive headlines\n",
        "    positive_mask = combined_df['headline_sentiment_label'] == 'positive'\n",
        "    if positive_mask.any():\n",
        "        positive_text = \" \".join(combined_df.loc[positive_mask, 'headline'].tolist())\n",
        "        wc_pos = WordCloud(width=800, height=400, background_color='white',\n",
        "                          stopwords=set(STOPWORDS), collocations=False).generate(positive_text)\n",
        "        wc_pos.to_file(f\"{Config.OUTPUT_DIR}/wordcloud_positive_headlines_original.png\")\n",
        "        print(\"Positive word cloud saved\")\n",
        "\n",
        "    # Negative headlines\n",
        "    negative_mask = combined_df['headline_sentiment_label'] == 'negative'\n",
        "    if negative_mask.any():\n",
        "        negative_text = \" \".join(combined_df.loc[negative_mask, 'headline'].tolist())\n",
        "        wc_neg = WordCloud(width=800, height=400, background_color='white',\n",
        "                          stopwords=set(STOPWORDS), collocations=False).generate(negative_text)\n",
        "        wc_neg.to_file(f\"{Config.OUTPUT_DIR}/wordcloud_negative_headlines_original.png\")\n",
        "        print(\"Negative word cloud saved\")\n",
        "\n",
        "# 3. Sentiment by category bar chart\n",
        "if 'major_category' in combined_df.columns and 'headline_sentiment_score' in combined_df.columns:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    category_means = combined_df.groupby('major_category')['headline_sentiment_score'].mean().sort_values()\n",
        "    colors = plt.cm.viridis(np.linspace(0, 1, len(category_means)))\n",
        "    category_means.plot(kind='barh', color=colors)\n",
        "    plt.axvline(x=0, color='red', linestyle='--', alpha=0.7)\n",
        "    plt.xlabel(\"Average Sentiment Score\")\n",
        "    plt.title(\"Average Headline Sentiment by Category (Original)\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{Config.OUTPUT_DIR}/sentiment_by_category_original.png\", dpi=300)\n",
        "    plt.close()\n",
        "    print(\"Sentiment by category chart saved\")"
      ],
      "metadata": {
        "id": "cMmHHj7Mfuxk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9b3d918-133c-4f15-ca98-e334a3ac7e6d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phase 05 Visualizations\n",
            "============================================================\n",
            "Headline length histogram saved\n",
            "\n",
            " Description length histogram saved\n",
            "Positive word cloud saved\n",
            "Negative word cloud saved\n",
            "Sentiment by category chart saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistical Tests\n",
        "print(\"Phase 06: Statistical Tests\")\n",
        "\n",
        "statistical_results = {}\n",
        "\n",
        "# 1. One-sample t-test (original test)\n",
        "if 'headline_sentiment_score' in combined_df.columns:\n",
        "    sentiment_data = combined_df['headline_sentiment_score'].dropna()\n",
        "    if len(sentiment_data) > 0:\n",
        "        t_stat, p_value = ttest_1samp(sentiment_data, 0)\n",
        "        statistical_results['one_sample_t_test'] = {\n",
        "            't_statistic': float(t_stat),\n",
        "            'p_value': float(p_value),\n",
        "            'mean_sentiment': float(sentiment_data.mean()),\n",
        "            'sample_size': len(sentiment_data),\n",
        "            'significant': bool(p_value < 0.05) # Cast to Python bool\n",
        "        }\n",
        "        print(f\"One-sample t-test: t={t_stat:.4f}, p={p_value:.4f}\")\n",
        "\n",
        "# 2. Independent t-tests between datasets\n",
        "if 'dataset' in combined_df.columns and 'headline_sentiment_score' in combined_df.columns:\n",
        "    dataset_comparisons = []\n",
        "    datasets_list = combined_df['dataset'].unique()\n",
        "\n",
        "    for i in range(len(datasets_list)):\n",
        "        for j in range(i+1, len(datasets_list)):\n",
        "            d1, d2 = datasets_list[i], datasets_list[j]\n",
        "            sent1 = combined_df[combined_df['dataset'] == d1]['headline_sentiment_score'].dropna()\n",
        "            sent2 = combined_df[combined_df['dataset'] == d2]['headline_sentiment_score'].dropna()\n",
        "\n",
        "            if len(sent1) > 30 and len(sent2) > 30:\n",
        "                t_stat, p_value = ttest_ind(sent1, sent2, equal_var=False)\n",
        "                dataset_comparisons.append({\n",
        "                    'comparison': f\"{d1}_vs_{d2}\",\n",
        "                    't_statistic': float(t_stat),\n",
        "                    'p_value': float(p_value),\n",
        "                    'mean_1': float(sent1.mean()),\n",
        "                    'mean_2': float(sent2.mean()),\n",
        "                    'significant': bool(p_value < 0.05) # Cast to Python bool\n",
        "                })\n",
        "\n",
        "    statistical_results['dataset_comparisons'] = dataset_comparisons\n",
        "    print(f\"{len(dataset_comparisons)} dataset comparisons completed\")\n",
        "\n",
        "# 3. ANOVA across categories\n",
        "if 'major_category' in combined_df.columns and 'headline_sentiment_score' in combined_df.columns:\n",
        "    categories = combined_df['major_category'].unique()\n",
        "    anova_data = []\n",
        "\n",
        "    for cat in categories:\n",
        "        cat_data = combined_df[combined_df['major_category'] == cat]['headline_sentiment_score'].dropna()\n",
        "        if len(cat_data) > 30:\n",
        "            anova_data.append(cat_data)\n",
        "\n",
        "    if len(anova_data) >= 2:\n",
        "        f_stat, p_value = f_oneway(*anova_data)\n",
        "        statistical_results['anova_test'] = {\n",
        "            'f_statistic': float(f_stat),\n",
        "            'p_value': float(p_value),\n",
        "            'n_categories': len(anova_data),\n",
        "            'significant': bool(p_value < 0.05) # Cast to Python bool\n",
        "        }\n",
        "        print(f\"ANOVA test: F={f_stat:.4f}, p={p_value:.4f}\")\n",
        "\n",
        "# Save statistical results\n",
        "with open(f\"{Config.REPORTS_DIR}/statistical_results_original.json\", \"w\") as f:\n",
        "    json.dump(statistical_results, f, indent=2)\n",
        "print(\"Statistical results saved\")"
      ],
      "metadata": {
        "id": "vrWtSiAjgD96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "826f41bd-7667-4d81-da05-1a07c763ba39"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phase 06: Statistical Tests\n",
            "One-sample t-test: t=-20.2983, p=0.0000\n",
            "1 dataset comparisons completed\n",
            "ANOVA test: F=2305.0802, p=0.0000\n",
            "Statistical results saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 07: Machine Learning Pipeline\n",
        "print(\"Phase 07: Machine Learning Pipeline\")\n",
        "\n",
        "def prepare_ml_data(df):\n",
        "    \"\"\"\n",
        "    Prepare data for machine learning models\n",
        "    \"\"\"\n",
        "    ml_df = df.copy()\n",
        "\n",
        "    # Create features\n",
        "    features = {}\n",
        "\n",
        "    # 1. Numerical features (from original preprocessing)\n",
        "    numerical_features = []\n",
        "    if 'headline_len_words' in ml_df.columns:\n",
        "        numerical_features.append('headline_len_words')\n",
        "    if 'description_len_words' in ml_df.columns:\n",
        "        numerical_features.append('description_len_words')\n",
        "    if 'headline_sentiment_score' in ml_df.columns:\n",
        "        numerical_features.append('headline_sentiment_score')\n",
        "    if 'description_sentiment_score' in ml_df.columns:\n",
        "        numerical_features.append('description_sentiment_score')\n",
        "\n",
        "    # 2. Text features\n",
        "    text_features = []\n",
        "    if 'headline' in ml_df.columns:\n",
        "        text_features.append('headline')\n",
        "    if 'description' in ml_df.columns:\n",
        "        text_features.append('description')\n",
        "\n",
        "    # 3. Categorical features\n",
        "    categorical_features = []\n",
        "    if 'major_category' in ml_df.columns:\n",
        "        categorical_features.append('major_category')\n",
        "    if 'dataset' in ml_df.columns:\n",
        "        categorical_features.append('dataset')\n",
        "    if 'source' in ml_df.columns:\n",
        "        categorical_features.append('source')\n",
        "\n",
        "    # 4. Target variable (using original sentiment labels)\n",
        "    target = None\n",
        "    if 'headline_sentiment_label' in ml_df.columns:\n",
        "        target = 'headline_sentiment_label'\n",
        "\n",
        "    return ml_df, numerical_features, text_features, categorical_features, target\n",
        "\n",
        "# Prepare ML data\n",
        "ml_df, num_features, text_features, cat_features, target = prepare_ml_data(combined_df)\n",
        "\n",
        "print(f\" Features identified:\")\n",
        "print(f\"  - Numerical: {num_features}\")\n",
        "print(f\"  - Text: {text_features}\")\n",
        "print(f\"  - Categorical: {cat_features}\")\n",
        "print(f\"  - Target: {target}\")"
      ],
      "metadata": {
        "id": "LMpRIEBrgdNr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08862700-ac1a-42b5-a7d6-561c75e03249"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phase 07: Machine Learning Pipeline\n",
            " Features identified:\n",
            "  - Numerical: ['headline_len_words', 'description_len_words', 'headline_sentiment_score', 'description_sentiment_score']\n",
            "  - Text: ['headline', 'description']\n",
            "  - Categorical: ['major_category', 'dataset', 'source']\n",
            "  - Target: headline_sentiment_label\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment Classification\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "if target and len(ml_df[target].unique()) >= 2:\n",
        "    print(\"\\n\" + \"-\" * 50)\n",
        "    print(\"TASK 1: SENTIMENT CLASSIFICATION\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Prepare data (initial X will still contain raw features for ColumnTransformer)\n",
        "    X = ml_df[num_features + text_features + cat_features].copy()\n",
        "    y = ml_df[target].copy()\n",
        "\n",
        "    # Encode target\n",
        "    le_target = LabelEncoder()\n",
        "    y_encoded = le_target.fit_transform(y)\n",
        "\n",
        "    # Define preprocessor using ColumnTransformer\n",
        "    # Numerical features: scale\n",
        "    # Categorical features: one-hot encode (to avoid ordinality issues)\n",
        "    # Text features: TF-IDF vectorization\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', StandardScaler(), num_features),\n",
        "            ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features),\n",
        "            ('text_headline', TfidfVectorizer(stop_words='english', max_features=5000), 'headline'),\n",
        "            ('text_description', TfidfVectorizer(stop_words='english', max_features=5000), 'description')\n",
        "        ],\n",
        "        remainder='passthrough'\n",
        "    )\n",
        "\n",
        "    # Split data before fitting preprocessor to avoid data leakage\n",
        "    X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
        "        X, y_encoded, test_size=Config.TEST_SIZE, random_state=Config.RANDOM_STATE, stratify=y_encoded\n",
        "    )\n",
        "\n",
        "    # Fit preprocessor on training data and transform both train and test\n",
        "    X_train = preprocessor.fit_transform(X_train_raw)\n",
        "    X_test = preprocessor.transform(X_test_raw)\n",
        "\n",
        "    print(f\"  Training samples: {X_train.shape[0]}\")\n",
        "    print(f\"  Testing samples: {X_test.shape[0]}\")\n",
        "    print(f\"  Classes: {le_target.classes_}\")\n",
        "\n",
        "    # Train multiple classifiers\n",
        "    classifiers = {\n",
        "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=Config.RANDOM_STATE),\n",
        "        'Logistic Regression': LogisticRegression(max_iter=1000, random_state=Config.RANDOM_STATE),\n",
        "        'Gradient Boosting': GradientBoostingClassifier(random_state=Config.RANDOM_STATE)\n",
        "    }\n",
        "\n",
        "    classification_results = {}\n",
        "\n",
        "    for clf_name, clf in classifiers.items():\n",
        "        print(f\"\\n  Training {clf_name}...\")\n",
        "\n",
        "        # Train\n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "        # Predict\n",
        "        y_pred = clf.predict(X_test)\n",
        "        y_pred_proba = clf.predict_proba(X_test) if hasattr(clf, \"predict_proba\") else None\n",
        "\n",
        "        # Evaluate\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "        precision = precision_score(y_test, y_pred, average='weighted')\n",
        "        recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "        classification_results[clf_name] = {\n",
        "            'accuracy': float(accuracy),\n",
        "            'f1_score': float(f1),\n",
        "            'precision': float(precision),\n",
        "            'recall': float(recall),\n",
        "            'model': clf\n",
        "        }\n",
        "\n",
        "        print(f\"    Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"    F1 Score: {f1:.4f}\")\n",
        "\n",
        "        # Save classification report\n",
        "        report = classification_report(y_test, y_pred, target_names=le_target.classes_, output_dict=True)\n",
        "        report_df = pd.DataFrame(report).transpose()\n",
        "        report_df.to_csv(f\"{Config.REPORTS_DIR}/classification_report_{clf_name.lower().replace(' ', '_')}.csv\")\n",
        "\n",
        "        # Save confusion matrix\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        cm_df = pd.DataFrame(cm, index=le_target.classes_, columns=le_target.classes_)\n",
        "        cm_df.to_csv(f\"{Config.REPORTS_DIR}/confusion_matrix_{clf_name.lower().replace(' ', '_')}.csv\")\n",
        "\n",
        "    # Save best model\n",
        "    best_clf_name = max(classification_results, key=lambda x: classification_results[x]['f1_score'])\n",
        "    best_clf = classification_results[best_clf_name]['model']\n",
        "    joblib.dump(best_clf, f\"{Config.MODELS_DIR}/best_classifier.pkl\")\n",
        "    joblib.dump(le_target, f\"{Config.MODELS_DIR}/label_encoder.pkl\")\n",
        "    joblib.dump(preprocessor, f\"{Config.MODELS_DIR}/preprocessor.pkl\") # Save the preprocessor too\n",
        "\n",
        "    print(f\"\\n  Best classifier: {best_clf_name}\")\n",
        "    print(f\"  Models saved to {Config.MODELS_DIR}/\")\n"
      ],
      "metadata": {
        "id": "FfeHbC0Hg2NE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "081fe313-9a32-4dcf-a05f-4a3ce3ef4e54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "TASK 1: SENTIMENT CLASSIFICATION\n",
            "--------------------------------------------------\n",
            "  Training samples: 173589\n",
            "  Testing samples: 43398\n",
            "  Classes: ['negative' 'neutral' 'positive']\n",
            "\n",
            "  Training Random Forest...\n",
            "    Accuracy: 0.9889\n",
            "    F1 Score: 0.9889\n",
            "\n",
            "  Training Logistic Regression...\n",
            "    Accuracy: 0.9979\n",
            "    F1 Score: 0.9979\n",
            "\n",
            "  Training Gradient Boosting...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Topic Modeling\n",
        "if 'headline' in ml_df.columns and 'description' in ml_df.columns:\n",
        "    print(\"Task 02: Topic Modeling (LDA)\")\n",
        "\n",
        "    # Combine text\n",
        "    combined_text = ml_df['headline'] + \" \" + ml_df['description']\n",
        "\n",
        "    # Vectorize\n",
        "    vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
        "    dtm = vectorizer.fit_transform(combined_text)\n",
        "\n",
        "    # Apply LDA\n",
        "    lda = LatentDirichletAllocation(\n",
        "        n_components=Config.N_CLUSTERS,\n",
        "        random_state=Config.RANDOM_STATE,\n",
        "        max_iter=10\n",
        "    )\n",
        "    lda.fit(dtm)\n",
        "\n",
        "    # Get topic distribution\n",
        "    topic_distribution = lda.transform(dtm)\n",
        "    ml_df['dominant_topic'] = topic_distribution.argmax(axis=1)\n",
        "\n",
        "    # Display topics\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "    print(\"\\n  Top words per topic:\")\n",
        "    for topic_idx, topic in enumerate(lda.components_):\n",
        "        top_words_idx = topic.argsort()[-10:][::-1]\n",
        "        top_words = [feature_names[i] for i in top_words_idx]\n",
        "        print(f\"  Topic {topic_idx}: {', '.join(top_words)}\")\n",
        "\n",
        "    # Save topic modeling results\n",
        "    topic_results = {\n",
        "        'topics': {},\n",
        "        'document_topic_distribution': topic_distribution.tolist(),\n",
        "        'dominant_topics': ml_df['dominant_topic'].tolist()\n",
        "    }\n",
        "\n",
        "    for topic_idx in range(Config.N_CLUSTERS):\n",
        "        top_words_idx = lda.components_[topic_idx].argsort()[-15:][::-1]\n",
        "        top_words = [feature_names[i] for i in top_words_idx]\n",
        "        topic_results['topics'][f'topic_{topic_idx}'] = top_words\n",
        "\n",
        "    with open(f\"{Config.REPORTS_DIR}/topic_modeling_results.json\", \"w\") as f:\n",
        "        json.dump(topic_results, f, indent=2)\n",
        "\n",
        "    # Save model\n",
        "    joblib.dump(lda, f\"{Config.MODELS_DIR}/lda_model.pkl\")\n",
        "    joblib.dump(vectorizer, f\"{Config.MODELS_DIR}/vectorizer.pkl\")\n",
        "\n",
        "    print(f\"  Topics identified: {Config.N_CLUSTERS}\")\n",
        "    print(f\"  Topic modeling results saved\")"
      ],
      "metadata": {
        "id": "mEdHFok5hTjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clustering Analysis\n",
        "if len(num_features) >= 2:\n",
        "    print(\"\\n\" + \"-\" * 50)\n",
        "    print(\"Task 03: Clustering Analysis\")\n",
        "\n",
        "    # Prepare numerical data\n",
        "    cluster_data = ml_df[num_features].fillna(0)\n",
        "\n",
        "    # Standardize\n",
        "    scaler = StandardScaler()\n",
        "    cluster_scaled = scaler.fit_transform(cluster_data)\n",
        "\n",
        "    # KMeans clustering\n",
        "    kmeans = KMeans(n_clusters=Config.N_CLUSTERS, random_state=Config.RANDOM_STATE)\n",
        "    cluster_labels = kmeans.fit_predict(cluster_scaled)\n",
        "    ml_df['cluster'] = cluster_labels\n",
        "\n",
        "    # Evaluate clustering\n",
        "    silhouette = silhouette_score(cluster_scaled, cluster_labels)\n",
        "    calinski = calinski_harabasz_score(cluster_scaled, cluster_labels)\n",
        "\n",
        "    print(f\"  Clustering Evaluation:\")\n",
        "    print(f\"    Silhouette Score: {silhouette:.4f}\")\n",
        "    print(f\"    Calinski-Harabasz Score: {calinski:.4f}\")\n",
        "\n",
        "    # Analyze clusters\n",
        "    cluster_stats = {}\n",
        "    for cluster_id in range(Config.N_CLUSTERS):\n",
        "        cluster_mask = ml_df['cluster'] == cluster_id\n",
        "        cluster_df = ml_df[cluster_mask]\n",
        "\n",
        "        cluster_stats[cluster_id] = {\n",
        "            'size': int(cluster_mask.sum()),\n",
        "            'avg_headline_length': float(cluster_df['headline_len_words'].mean()) if 'headline_len_words' in cluster_df.columns else None,\n",
        "            'avg_sentiment': float(cluster_df['headline_sentiment_score'].mean()) if 'headline_sentiment_score' in cluster_df.columns else None,\n",
        "            'common_categories': cluster_df['major_category'].value_counts().head(3).to_dict() if 'major_category' in cluster_df.columns else None\n",
        "        }\n",
        "\n",
        "    # Save clustering results\n",
        "    with open(f\"{Config.REPORTS_DIR}/clustering_results.json\", \"w\") as f:\n",
        "        json.dump({\n",
        "            'silhouette_score': float(silhouette),\n",
        "            'calinski_harabasz_score': float(calinski),\n",
        "            'cluster_statistics': cluster_stats\n",
        "        }, f, indent=2)\n",
        "\n",
        "    # Save model\n",
        "    joblib.dump(kmeans, f\"{Config.MODELS_DIR}/kmeans_model.pkl\")\n",
        "    joblib.dump(scaler, f\"{Config.MODELS_DIR}/clustering_scaler.pkl\")\n",
        "\n",
        "    print(f\"  {Config.N_CLUSTERS} clusters created\")\n",
        "    print(f\"  Clustering results saved\")"
      ],
      "metadata": {
        "id": "8rj4ZwCfhk3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Time Series Analysis\n",
        "if 'date' in ml_df.columns and 'headline_sentiment_score' in ml_df.columns:\n",
        "    print(\"Task 04: Time Series Analysis\")\n",
        "\n",
        "    try:\n",
        "        # Convert date column\n",
        "        ml_df['date'] = pd.to_datetime(ml_df['date'], errors='coerce')\n",
        "        ml_df = ml_df.dropna(subset=['date'])\n",
        "\n",
        "        # Set date as index\n",
        "        time_series = ml_df.set_index('date').sort_index()\n",
        "\n",
        "        # Resample sentiment by day\n",
        "        daily_sentiment = time_series['headline_sentiment_score'].resample('D').mean()\n",
        "\n",
        "        # Calculate moving averages\n",
        "        weekly_ma = daily_sentiment.rolling(window=7, min_periods=1).mean()\n",
        "        monthly_ma = daily_sentiment.rolling(window=30, min_periods=1).mean()\n",
        "\n",
        "        # Plot time series\n",
        "        plt.figure(figsize=(15, 8))\n",
        "        plt.plot(daily_sentiment.index, daily_sentiment.values, alpha=0.3, label='Daily', color='gray')\n",
        "        plt.plot(weekly_ma.index, weekly_ma.values, linewidth=2, label='7-Day MA', color='blue')\n",
        "        plt.plot(monthly_ma.index, monthly_ma.values, linewidth=2, label='30-Day MA', color='red')\n",
        "        plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
        "        plt.xlabel('Date')\n",
        "        plt.ylabel('Average Sentiment Score')\n",
        "        plt.title('Sentiment Trends Over Time')\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{Config.OUTPUT_DIR}/sentiment_time_series.png\", dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "        # Calculate statistics\n",
        "        time_stats = {\n",
        "            'date_range': {\n",
        "                'start': daily_sentiment.index.min().strftime('%Y-%m-%d'),\n",
        "                'end': daily_sentiment.index.max().strftime('%Y-%m-%d'),\n",
        "                'days': len(daily_sentiment)\n",
        "            },\n",
        "            'overall_trend': 'increasing' if daily_sentiment.iloc[-1] > daily_sentiment.iloc[0] else 'decreasing',\n",
        "            'volatility': float(daily_sentiment.std()),\n",
        "            'average_sentiment': float(daily_sentiment.mean())\n",
        "        }\n",
        "\n",
        "        # Save time series results\n",
        "        with open(f\"{Config.REPORTS_DIR}/time_series_results.json\", \"w\") as f:\n",
        "            json.dump(time_stats, f, indent=2)\n",
        "\n",
        "        # Save daily sentiment data\n",
        "        daily_sentiment.to_csv(f\"{Config.OUTPUT_DIR}/daily_sentiment.csv\")\n",
        "\n",
        "        print(f\"  Time series analyzed: {time_stats['date_range']['days']} days\")\n",
        "        print(f\"  Overall trend: {time_stats['overall_trend']}\")\n",
        "        print(f\"  Charts and data saved\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  Time series analysis skipped: {str(e)}\")"
      ],
      "metadata": {
        "id": "9KQI2HY3c3au"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Summary\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"PHASE 8: FINAL REPORT & SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create comprehensive report\n",
        "final_report = {\n",
        "    'project_info': {\n",
        "        'name': 'News Sentiment Analysis Pipeline',\n",
        "        'datasets_used': list(Config.DATA_FILES.keys()),\n",
        "        'total_samples': len(combined_df),\n",
        "        'preprocessing_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "    },\n",
        "    'preprocessing_summary': {\n",
        "        'original_columns_kept': list(combined_df.columns),\n",
        "        'category_distribution': combined_df['major_category'].value_counts().to_dict() if 'major_category' in combined_df.columns else None,\n",
        "        'sentiment_distribution': combined_df['headline_sentiment_label'].value_counts().to_dict() if 'headline_sentiment_label' in combined_df.columns else None\n",
        "    },\n",
        "    'analysis_performed': {\n",
        "        'statistical_tests': list(statistical_results.keys()) if statistical_results else [],\n",
        "        'machine_learning_tasks': ['Sentiment Classification', 'Topic Modeling', 'Clustering', 'Time Series Analysis'],\n",
        "        'visualizations_created': [\n",
        "            'headline_length_hist_original.png',\n",
        "            'description_length_hist_original.png',\n",
        "            'wordcloud_positive_headlines_original.png',\n",
        "            'wordcloud_negative_headlines_original.png',\n",
        "            'sentiment_by_category_original.png',\n",
        "            'sentiment_time_series.png'\n",
        "        ]\n",
        "    },\n",
        "    'models_saved': {\n",
        "        'classification': 'best_classifier.pkl' if os.path.exists(f\"{Config.MODELS_DIR}/best_classifier.pkl\") else None,\n",
        "        'topic_modeling': ['lda_model.pkl', 'vectorizer.pkl'] if os.path.exists(f\"{Config.MODELS_DIR}/lda_model.pkl\") else None,\n",
        "        'clustering': ['kmeans_model.pkl', 'clustering_scaler.pkl'] if os.path.exists(f\"{Config.MODELS_DIR}/kmeans_model.pkl\") else None\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save final report\n",
        "with open(f\"{Config.REPORTS_DIR}/final_project_report.json\", \"w\") as f:\n",
        "    json.dump(final_report, f, indent=2)\n",
        "\n",
        "# Create summary CSV\n",
        "summary_data = {\n",
        "    'Metric': [\n",
        "        'Total Articles',\n",
        "        'Number of Datasets',\n",
        "        'Unique Categories',\n",
        "        'Unique Sources',\n",
        "        'Average Headline Length',\n",
        "        'Average Description Length',\n",
        "        'Average Sentiment Score',\n",
        "        'Positive Articles (%)',\n",
        "        'Negative Articles (%)',\n",
        "        'Neutral Articles (%)'\n",
        "    ],\n",
        "    'Value': [\n",
        "        len(combined_df),\n",
        "        len(combined_df['dataset'].unique()) if 'dataset' in combined_df.columns else 0,\n",
        "        len(combined_df['major_category'].unique()) if 'major_category' in combined_df.columns else 0,\n",
        "        len(combined_df['source'].unique()) if 'source' in combined_df.columns else 0,\n",
        "        combined_df['headline_len_words'].mean() if 'headline_len_words' in combined_df.columns else 0,\n",
        "        combined_df['description_len_words'].mean() if 'description_len_words' in combined_df.columns else 0,\n",
        "        combined_df['headline_sentiment_score'].mean() if 'headline_sentiment_score' in combined_df.columns else 0,\n",
        "        (combined_df['headline_sentiment_label'] == 'positive').mean() * 100 if 'headline_sentiment_label' in combined_df.columns else 0,\n",
        "        (combined_df['headline_sentiment_label'] == 'negative').mean() * 100 if 'headline_sentiment_label' in combined_df.columns else 0,\n",
        "        (combined_df['headline_sentiment_label'] == 'neutral').mean() * 100 if 'headline_sentiment_label' in combined_df.columns else 0\n",
        "    ]\n",
        "}\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "summary_df.to_csv(f\"{Config.REPORTS_DIR}/project_summary.csv\", index=False)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"PROJECT COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\n OUTPUT STRUCTURE:\")\n",
        "print(f\"  {Config.OUTPUT_DIR}/\")\n",
        "print(f\"    ├── Integrated_Three_Datasets.csv\")\n",
        "print(f\"    ├── summary_statistics_original.csv\")\n",
        "print(f\"    ├── avg_sentiment_by_source_original.csv\")\n",
        "print(f\"    ├── avg_sentiment_by_category_original.csv\")\n",
        "print(f\"    ├── headline_length_hist_original.png\")\n",
        "print(f\"    ├── description_length_hist_original.png\")\n",
        "print(f\"    ├── wordcloud_positive_headlines_original.png\")\n",
        "print(f\"    ├── wordcloud_negative_headlines_original.png\")\n",
        "print(f\"    ├── sentiment_by_category_original.png\")\n",
        "print(f\"    └── sentiment_time_series.png\")\n",
        "\n",
        "print(f\"\\n  {Config.MODELS_DIR}/\")\n",
        "print(f\"    ├── best_classifier.pkl\")\n",
        "print(f\"    ├── label_encoder.pkl\")\n",
        "print(f\"    ├── lda_model.pkl\")\n",
        "print(f\"    ├── vectorizer.pkl\")\n",
        "print(f\"    ├── kmeans_model.pkl\")\n",
        "print(f\"    └── clustering_scaler.pkl\")\n",
        "\n",
        "print(f\"\\n  {Config.REPORTS_DIR}/\")\n",
        "print(f\"    ├── statistical_results_original.json\")\n",
        "print(f\"    ├── classification_report_*.csv\")\n",
        "print(f\"    ├── confusion_matrix_*.csv\")\n",
        "print(f\"    ├── topic_modeling_results.json\")\n",
        "print(f\"    ├── clustering_results.json\")\n",
        "print(f\"    ├── time_series_results.json\")\n",
        "print(f\"    ├── final_project_report.json\")\n",
        "print(f\"    └── project_summary.csv\")\n",
        "\n",
        "print(\"\\nKEY STATISTICS:\")\n",
        "print(f\"  Total articles analyzed: {len(combined_df)}\")\n",
        "if 'major_category' in combined_df.columns:\n",
        "    print(f\"  Categories found: {', '.join(combined_df['major_category'].unique())}\")\n",
        "if 'headline_sentiment_label' in combined_df.columns:\n",
        "    sentiment_counts = combined_df['headline_sentiment_label'].value_counts()\n",
        "    for label, count in sentiment_counts.items():\n",
        "        percentage = (count / len(combined_df)) * 100\n",
        "        print(f\"  {label.capitalize()} articles: {count} ({percentage:.1f}%)\")\n",
        "\n",
        "print(\"\\nPipeline completed! All outputs saved successfully.\")"
      ],
      "metadata": {
        "id": "Br95YC_gv5Bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Story Evolution Tracking & News Cycle Patterns**"
      ],
      "metadata": {
        "id": "s-ndPlcWR0AI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "hxqOA6DTSA9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# Configuration Plug & Play Settings\n",
        "# ============================================================================\n",
        "\n",
        "class StoryConfig:\n",
        "    \"\"\"Configuration parameters for story evolution tracking\"\"\"\n",
        "\n",
        "    # Story Identification\n",
        "    SIMILARITY_THRESHOLD = 0.6  # Minimum cosine similarity for same story\n",
        "    TIME_WINDOW_DAYS = 7  # Maximum days between articles to be same story\n",
        "    MIN_STORY_SIZE = 3  # Minimum articles per story\n",
        "\n",
        "    # Text Processing\n",
        "    USE_EMBEDDINGS = False  # Set to True for BERT embeddings (slower but better)\n",
        "    TFIDF_MAX_FEATURES = 5000\n",
        "    MIN_DF = 2\n",
        "    MAX_DF = 0.95\n",
        "\n",
        "    # Clustering (alternative to similarity-based)\n",
        "    CLUSTERING_METHOD = 'similarity'  # 'similarity' or 'dbscan'\n",
        "    DBSCAN_EPS = 0.5\n",
        "    DBSCAN_MIN_SAMPLES = 2\n",
        "\n",
        "    # Entity Extraction\n",
        "    ENTITY_TYPES = ['PERSON', 'ORG', 'GPE', 'LOC', 'NORP']  # SpaCy entity types\n",
        "    MIN_ENTITY_FREQ = 2  # Minimum mentions to track\n",
        "\n",
        "    # News Cycle Analysis\n",
        "    DECAY_THRESHOLD = 0.1  # Threshold for decay detection\n",
        "    RESURGENCE_WINDOW_DAYS = 3  # Days of inactivity before checking resurgence\n",
        "    PEAK_THRESHOLD_MULTIPLIER = 2.0  # Multiplier of mean for peak detection\n",
        "\n",
        "    # Visualization\n",
        "    PLOT_COLORS = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
        "    FIGURE_SIZE = (15, 10)\n",
        "\n",
        "    # Output Paths (extending existing structure)\n",
        "    STORIES_DIR = \"outputs/stories\"\n",
        "    EVOLUTION_DIR = \"outputs/evolution\"\n",
        "    PATTERNS_DIR = \"outputs/patterns\"\n",
        "\n",
        "# Create directories\n",
        "import os\n",
        "for dir_path in [StoryConfig.STORIES_DIR, StoryConfig.EVOLUTION_DIR, StoryConfig.PATTERNS_DIR]:\n",
        "    os.makedirs(dir_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "9aKg9VwdRvvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Story Evolution Tracking**"
      ],
      "metadata": {
        "id": "upvEauqNTNhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# Story Evolution Tracking\n",
        "# ============================================================================\n",
        "\n",
        "def preprocess_for_story_detection(df):\n",
        "    \"\"\"\n",
        "    Prepare text data for story detection\n",
        "    Extends existing preprocessing without modifying original data\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with 'headline' and 'description' columns\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with additional processed columns\n",
        "    \"\"\"\n",
        "    story_df = df.copy()\n",
        "\n",
        "    # Combine text fields for better story detection\n",
        "    if 'headline' in story_df.columns and 'description' in story_df.columns:\n",
        "        story_df['full_text'] = story_df['headline'] + '. ' + story_df['description'].fillna('')\n",
        "    elif 'headline' in story_df.columns:\n",
        "        story_df['full_text'] = story_df['headline']\n",
        "    else:\n",
        "        story_df['full_text'] = story_df['description']\n",
        "\n",
        "    # Clean text for similarity comparison\n",
        "    story_df['clean_text'] = story_df['full_text'].apply(\n",
        "        lambda x: ' '.join(str(x).lower().split()[:100])  # Limit to first 100 words\n",
        "    )\n",
        "\n",
        "    # Ensure datetime for temporal analysis\n",
        "    if 'date' in story_df.columns:\n",
        "        story_df['datetime'] = pd.to_datetime(story_df['date'], errors='coerce')\n",
        "    else:\n",
        "        # Create dummy datetime if not available\n",
        "        story_df['datetime'] = pd.Timestamp.now()\n",
        "\n",
        "    return story_df"
      ],
      "metadata": {
        "id": "gMB1yNXRSf7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_text_similarity(texts, method='tfidf'):\n",
        "    \"\"\"\n",
        "    Compute pairwise similarity between texts\n",
        "\n",
        "    Args:\n",
        "        texts: List of text strings\n",
        "        method: 'tfidf' or 'embeddings'\n",
        "\n",
        "    Returns:\n",
        "        similarity_matrix: numpy array of pairwise similarities\n",
        "        feature_vectors: computed features for reuse\n",
        "    \"\"\"\n",
        "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "    from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "    if method == 'tfidf':\n",
        "        vectorizer = TfidfVectorizer(\n",
        "            max_features=StoryConfig.TFIDF_MAX_FEATURES,\n",
        "            min_df=StoryConfig.MIN_DF,\n",
        "            max_df=StoryConfig.MAX_DF,\n",
        "            stop_words='english'\n",
        "        )\n",
        "        vectors = vectorizer.fit_transform(texts)\n",
        "        similarity_matrix = cosine_similarity(vectors)\n",
        "        return similarity_matrix, (vectorizer, vectors)\n",
        "\n",
        "    elif method == 'embeddings' and StoryConfig.USE_EMBEDDINGS:\n",
        "        # Using sentence transformers for better semantic similarity\n",
        "        from sentence_transformers import SentenceTransformer\n",
        "\n",
        "        model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        embeddings = model.encode(texts, show_progress_bar=False)\n",
        "        similarity_matrix = cosine_similarity(embeddings)\n",
        "        return similarity_matrix, embeddings\n",
        "\n",
        "    else:\n",
        "        # Fallback to TF-IDF\n",
        "        return compute_text_similarity(texts, method='tfidf')"
      ],
      "metadata": {
        "id": "zmd69299TeNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def identify_stories(df):\n",
        "    \"\"\"\n",
        "    Group articles into evolving stories using temporal and semantic similarity\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with preprocessed text and datetime\n",
        "\n",
        "    Returns:\n",
        "        df_with_stories: DataFrame with story_id column added\n",
        "        story_metadata: Dict with story information\n",
        "    \"\"\"\n",
        "    from datetime import timedelta\n",
        "\n",
        "    story_df = df.copy().reset_index(drop=True)\n",
        "    story_df['story_id'] = -1  # Initialize with no story\n",
        "\n",
        "    # Sort by datetime for temporal analysis\n",
        "    story_df = story_df.sort_values('datetime')\n",
        "\n",
        "    # Get clean texts\n",
        "    texts = story_df['clean_text'].tolist()\n",
        "\n",
        "    # Compute similarity matrix\n",
        "    similarity_matrix, _ = compute_text_similarity(texts)\n",
        "\n",
        "    # Initialize story tracking\n",
        "    current_story_id = 0\n",
        "    stories = {}\n",
        "\n",
        "    for i in range(len(story_df)):\n",
        "        if story_df.loc[i, 'story_id'] != -1:\n",
        "            continue  # Already assigned\n",
        "\n",
        "        # Start new story\n",
        "        story_df.loc[i, 'story_id'] = current_story_id\n",
        "        stories[current_story_id] = {\n",
        "            'articles': [i],\n",
        "            'start_date': story_df.loc[i, 'datetime'],\n",
        "            'keywords': set(story_df.loc[i, 'clean_text'].split()[:10])\n",
        "        }\n",
        "\n",
        "        # Find similar articles within time window\n",
        "        for j in range(i + 1, len(story_df)):\n",
        "            if story_df.loc[j, 'story_id'] != -1:\n",
        "                continue\n",
        "\n",
        "            time_diff = (story_df.loc[j, 'datetime'] - story_df.loc[i, 'datetime']).days\n",
        "\n",
        "            if time_diff > StoryConfig.TIME_WINDOW_DAYS:\n",
        "                break  # Articles too far apart in time\n",
        "\n",
        "            similarity = similarity_matrix[i, j]\n",
        "\n",
        "            if similarity >= StoryConfig.SIMILARITY_THRESHOLD:\n",
        "                story_df.loc[j, 'story_id'] = current_story_id\n",
        "                stories[current_story_id]['articles'].append(j)\n",
        "\n",
        "                # Update story end date\n",
        "                if story_df.loc[j, 'datetime'] > stories[current_story_id].get('end_date', story_df.loc[i, 'datetime']):\n",
        "                    stories[current_story_id]['end_date'] = story_df.loc[j, 'datetime']\n",
        "\n",
        "                # Update keywords\n",
        "                new_keywords = set(story_df.loc[j, 'clean_text'].split()[:10])\n",
        "                stories[current_story_id]['keywords'].update(new_keywords)\n",
        "\n",
        "        current_story_id += 1\n",
        "\n",
        "    # Filter out small stories\n",
        "    story_sizes = story_df['story_id'].value_counts()\n",
        "    valid_stories = story_sizes[story_sizes >= StoryConfig.MIN_STORY_SIZE].index\n",
        "\n",
        "    story_df = story_df[story_df['story_id'].isin(valid_stories)].copy()\n",
        "\n",
        "    # Reindex story IDs for cleaner output\n",
        "    story_mapping = {old_id: new_id for new_id, old_id in enumerate(valid_stories)}\n",
        "    story_df['story_id'] = story_df['story_id'].map(story_mapping)\n",
        "\n",
        "    # Update story metadata\n",
        "    final_stories = {}\n",
        "    for old_id, new_id in story_mapping.items():\n",
        "        article_indices = story_df[story_df['story_id'] == new_id].index.tolist()\n",
        "        story_articles = df.loc[article_indices].copy()\n",
        "\n",
        "        final_stories[new_id] = {\n",
        "            'size': len(article_indices),\n",
        "            'articles': story_articles,\n",
        "            'start_date': story_articles['datetime'].min(),\n",
        "            'end_date': story_articles['datetime'].max(),\n",
        "            'duration_days': (story_articles['datetime'].max() - story_articles['datetime'].min()).days + 1,\n",
        "            'sources': story_articles['source'].unique().tolist() if 'source' in story_articles.columns else [],\n",
        "            'categories': story_articles['major_category'].unique().tolist() if 'major_category' in story_articles.columns else []\n",
        "        }\n",
        "\n",
        "    return story_df, final_stories"
      ],
      "metadata": {
        "id": "ESpJoaFZSvbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_narrative_evolution(story_data):\n",
        "    \"\"\"\n",
        "    Track chronological changes in dominant keywords and topics within each story\n",
        "\n",
        "    Args:\n",
        "        story_data: Dict containing story information\n",
        "\n",
        "    Returns:\n",
        "        narrative_evolution: Dict with narrative evolution per story\n",
        "    \"\"\"\n",
        "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "    from collections import defaultdict\n",
        "\n",
        "    narrative_evolution = {}\n",
        "\n",
        "    for story_id, story_info in story_data.items():\n",
        "        articles = story_info['articles'].sort_values('datetime')\n",
        "\n",
        "        if len(articles) < 2:\n",
        "            continue\n",
        "\n",
        "        # Split timeline into phases\n",
        "        n_phases = min(3, len(articles))  # Max 3 phases for readability\n",
        "        phase_size = len(articles) // n_phases\n",
        "\n",
        "        phase_keywords = []\n",
        "        phase_sentiments = []\n",
        "        phase_dates = []\n",
        "\n",
        "        for phase in range(n_phases):\n",
        "            start_idx = phase * phase_size\n",
        "            end_idx = (phase + 1) * phase_size if phase < n_phases - 1 else len(articles)\n",
        "\n",
        "            phase_articles = articles.iloc[start_idx:end_idx]\n",
        "\n",
        "            # Extract keywords using TF-IDF\n",
        "            if 'full_text' in phase_articles.columns:\n",
        "                vectorizer = TfidfVectorizer(max_features=20, stop_words='english')\n",
        "                tfidf_matrix = vectorizer.fit_transform(phase_articles['full_text'])\n",
        "                feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "                # Get top keywords\n",
        "                tfidf_scores = tfidf_matrix.sum(axis=0).A1\n",
        "                top_indices = tfidf_scores.argsort()[-5:][::-1]\n",
        "                top_keywords = [feature_names[i] for i in top_indices]\n",
        "\n",
        "                phase_keywords.append(top_keywords)\n",
        "\n",
        "            # Calculate average sentiment\n",
        "            if 'headline_sentiment_score' in phase_articles.columns:\n",
        "                avg_sentiment = phase_articles['headline_sentiment_score'].mean()\n",
        "                phase_sentiments.append(avg_sentiment)\n",
        "\n",
        "            phase_dates.append(phase_articles['datetime'].min())\n",
        "\n",
        "        narrative_evolution[story_id] = {\n",
        "            'phases': n_phases,\n",
        "            'phase_dates': phase_dates,\n",
        "            'phase_keywords': phase_keywords,\n",
        "            'phase_sentiments': phase_sentiments,\n",
        "            'keyword_shift': len(set([kw for phase in phase_keywords for kw in phase])) > 10\n",
        "        }\n",
        "\n",
        "    return narrative_evolution"
      ],
      "metadata": {
        "id": "2lXrLtZ0S7nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_sentiment_evolution(story_data):\n",
        "    \"\"\"\n",
        "    Track sentiment trends and polarity shifts within stories\n",
        "\n",
        "    Args:\n",
        "        story_data: Dict containing story information\n",
        "\n",
        "    Returns:\n",
        "        sentiment_evolution: Dict with sentiment evolution metrics\n",
        "    \"\"\"\n",
        "    sentiment_evolution = {}\n",
        "\n",
        "    for story_id, story_info in story_data.items():\n",
        "        articles = story_info['articles'].sort_values('datetime')\n",
        "\n",
        "        if 'headline_sentiment_score' not in articles.columns:\n",
        "            continue\n",
        "\n",
        "        sentiments = articles['headline_sentiment_score'].values\n",
        "        dates = articles['datetime'].values\n",
        "\n",
        "        # Calculate sentiment metrics\n",
        "        sentiment_changes = np.diff(sentiments)\n",
        "        positive_shifts = np.sum(sentiment_changes > 0.2)  # Significant positive shift\n",
        "        negative_shifts = np.sum(sentiment_changes < -0.2)  # Significant negative shift\n",
        "\n",
        "        # Detect polarity reversal\n",
        "        polarity_reversal = False\n",
        "        if len(sentiments) >= 3:\n",
        "            for i in range(1, len(sentiments)-1):\n",
        "                if (sentiments[i-1] < -0.1 and sentiments[i+1] > 0.1) or \\\n",
        "                   (sentiments[i-1] > 0.1 and sentiments[i+1] < -0.1):\n",
        "                    polarity_reversal = True\n",
        "                    break\n",
        "\n",
        "        sentiment_evolution[story_id] = {\n",
        "            'initial_sentiment': float(sentiments[0]),\n",
        "            'final_sentiment': float(sentiments[-1]),\n",
        "            'sentiment_range': float(sentiments.max() - sentiments.min()),\n",
        "            'sentiment_volatility': float(np.std(sentiments)),\n",
        "            'positive_shifts': int(positive_shifts),\n",
        "            'negative_shifts': int(negative_shifts),\n",
        "            'polarity_reversal': polarity_reversal,\n",
        "            'sentiment_trend': 'positive' if sentiments[-1] > sentiments[0] else 'negative',\n",
        "            'sentiment_timeline': [\n",
        "                {'date': str(dates[i]), 'sentiment': float(sentiments[i])}\n",
        "                for i in range(len(sentiments))\n",
        "            ]\n",
        "        }\n",
        "\n",
        "    return sentiment_evolution"
      ],
      "metadata": {
        "id": "Eh8JM439TC44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_entities_from_stories(story_data):\n",
        "    \"\"\"\n",
        "    Extract and track named entities across story timeline\n",
        "\n",
        "    Args:\n",
        "        story_data: Dict containing story information\n",
        "\n",
        "    Returns:\n",
        "        entity_evolution: Dict with entity tracking per story\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import spacy\n",
        "        nlp = spacy.load(\"en_core_web_sm\")\n",
        "    except:\n",
        "        print(\"SpaCy not available. Installing en_core_web_sm...\")\n",
        "        import subprocess\n",
        "        subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"])\n",
        "        import spacy\n",
        "        nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "    entity_evolution = {}\n",
        "\n",
        "    for story_id, story_info in story_data.items():\n",
        "        articles = story_info['articles'].sort_values('datetime')\n",
        "\n",
        "        if 'full_text' not in articles.columns:\n",
        "            continue\n",
        "\n",
        "        # Split timeline into early, middle, and late phases\n",
        "        n_articles = len(articles)\n",
        "        early_cutoff = n_articles // 3\n",
        "        late_start = 2 * early_cutoff\n",
        "\n",
        "        entity_phases = {'early': [], 'middle': [], 'late': []}\n",
        "        entity_counts = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "        for idx, (_, article) in enumerate(articles.iterrows()):\n",
        "            text = article['full_text']\n",
        "            doc = nlp(str(text)[:1000])  # Process first 1000 chars for efficiency\n",
        "\n",
        "            phase = 'early' if idx < early_cutoff else 'late' if idx >= late_start else 'middle'\n",
        "\n",
        "            for ent in doc.ents:\n",
        "                if ent.label_ in StoryConfig.ENTITY_TYPES:\n",
        "                    entity_phases[phase].append(ent.text)\n",
        "                    entity_counts[ent.text][phase] += 1\n",
        "\n",
        "        # Analyze entity evolution\n",
        "        all_entities = set([ent for phase in entity_phases.values() for ent in phase])\n",
        "        entity_analysis = {}\n",
        "\n",
        "        for entity in all_entities:\n",
        "            phase_presence = {\n",
        "                'early': entity_counts[entity]['early'] > 0,\n",
        "                'middle': entity_counts[entity]['middle'] > 0,\n",
        "                'late': entity_counts[entity]['late'] > 0\n",
        "            }\n",
        "\n",
        "            # Classify entity pattern\n",
        "            if phase_presence['early'] and not phase_presence['late']:\n",
        "                pattern = 'early_only'\n",
        "            elif not phase_presence['early'] and phase_presence['late']:\n",
        "                pattern = 'late_emerging'\n",
        "            elif phase_presence['early'] and phase_presence['late']:\n",
        "                pattern = 'persistent'\n",
        "            else:\n",
        "                pattern = 'middle_only'\n",
        "\n",
        "            entity_analysis[entity] = {\n",
        "                'pattern': pattern,\n",
        "                'counts': dict(entity_counts[entity]),\n",
        "                'total_mentions': sum(entity_counts[entity].values())\n",
        "            }\n",
        "\n",
        "        # Filter for significant entities\n",
        "        significant_entities = {\n",
        "            ent: info for ent, info in entity_analysis.items()\n",
        "            if info['total_mentions'] >= StoryConfig.MIN_ENTITY_FREQ\n",
        "        }\n",
        "\n",
        "        entity_evolution[story_id] = {\n",
        "            'entity_phases': dict(entity_phases),\n",
        "            'entity_analysis': significant_entities,\n",
        "            'early_entities': [ent for ent, info in significant_entities.items()\n",
        "                              if info['pattern'] in ['early_only', 'persistent']],\n",
        "            'late_entities': [ent for ent, info in significant_entities.items()\n",
        "                             if info['pattern'] in ['late_emerging', 'persistent']],\n",
        "            'entity_turnover': len(significant_entities) > 0\n",
        "        }\n",
        "\n",
        "    return entity_evolution"
      ],
      "metadata": {
        "id": "HT_9diiEU1_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_framing_evolution(story_data):\n",
        "    \"\"\"\n",
        "    Detect shifts in news framing across story timeline\n",
        "\n",
        "    Args:\n",
        "        story_data: Dict containing story information\n",
        "\n",
        "    Returns:\n",
        "        framing_evolution: Dict with framing analysis per story\n",
        "    \"\"\"\n",
        "    framing_keywords = {\n",
        "        'breaking': ['breaking', 'latest', 'urgent', 'developing', 'just in'],\n",
        "        'analysis': ['analysis', 'explainer', 'why', 'because', 'reason'],\n",
        "        'impact': ['impact', 'effect', 'consequence', 'result', 'outcome'],\n",
        "        'reaction': ['react', 'response', 'comment', 'statement', 'said'],\n",
        "        'resolution': ['resolve', 'solution', 'agreement', 'deal', 'settlement']\n",
        "    }\n",
        "\n",
        "    framing_evolution = {}\n",
        "\n",
        "    for story_id, story_info in story_data.items():\n",
        "        articles = story_info['articles'].sort_values('datetime')\n",
        "\n",
        "        if 'full_text' not in articles.columns:\n",
        "            continue\n",
        "\n",
        "        # Split into temporal segments\n",
        "        n_segments = min(4, len(articles))\n",
        "        segment_size = len(articles) // n_segments\n",
        "\n",
        "        framing_scores = {frame: [] for frame in framing_keywords.keys()}\n",
        "        dominant_frames = []\n",
        "\n",
        "        for segment in range(n_segments):\n",
        "            start_idx = segment * segment_size\n",
        "            end_idx = (segment + 1) * segment_size if segment < n_segments - 1 else len(articles)\n",
        "\n",
        "            segment_text = ' '.join(\n",
        "                articles.iloc[start_idx:end_idx]['full_text'].astype(str).tolist()\n",
        "            ).lower()\n",
        "\n",
        "            # Score each framing type\n",
        "            segment_scores = {}\n",
        "            for frame_type, keywords in framing_keywords.items():\n",
        "                score = sum(1 for kw in keywords if kw in segment_text)\n",
        "                segment_scores[frame_type] = score\n",
        "                framing_scores[frame_type].append(score)\n",
        "\n",
        "            # Determine dominant frame for segment\n",
        "            if sum(segment_scores.values()) > 0:\n",
        "                dominant_frame = max(segment_scores.items(), key=lambda x: x[1])[0]\n",
        "                dominant_frames.append(dominant_frame)\n",
        "            else:\n",
        "                dominant_frames.append('unknown')\n",
        "\n",
        "        # Detect framing shifts\n",
        "        framing_shifts = []\n",
        "        for i in range(1, len(dominant_frames)):\n",
        "            if dominant_frames[i] != dominant_frames[i-1]:\n",
        "                framing_shifts.append({\n",
        "                    'from': dominant_frames[i-1],\n",
        "                    'to': dominant_frames[i],\n",
        "                    'segment': i\n",
        "                })\n",
        "\n",
        "        framing_evolution[story_id] = {\n",
        "            'framing_scores': {k: [float(v) for v in vals] for k, vals in framing_scores.items()},\n",
        "            'dominant_frames': dominant_frames,\n",
        "            'framing_shifts': framing_shifts,\n",
        "            'framing_diversity': len(set(dominant_frames)),\n",
        "            'has_breaking_to_analysis': 'breaking' in dominant_frames and 'analysis' in dominant_frames and\n",
        "                                       dominant_frames.index('breaking') < dominant_frames.index('analysis')\n",
        "        }\n",
        "\n",
        "    return framing_evolution"
      ],
      "metadata": {
        "id": "bc3XSSUrTHgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **News Cycle Pattern Analysis**"
      ],
      "metadata": {
        "id": "RjUjJm-OVM28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# News Cycle Pattern Analysis\n",
        "# ============================================\n",
        "\n",
        "def analyze_story_lifespan(story_data):\n",
        "    \"\"\"\n",
        "    Measure duration and classify stories based on lifespan\n",
        "\n",
        "    Args:\n",
        "        story_data: Dict containing story information\n",
        "\n",
        "    Returns:\n",
        "        lifespan_analysis: Dict with lifespan metrics and classifications\n",
        "    \"\"\"\n",
        "    lifespans = []\n",
        "    for story_id, story_info in story_data.items():\n",
        "        duration = story_info['duration_days']\n",
        "        lifespans.append({\n",
        "            'story_id': story_id,\n",
        "            'duration_days': duration,\n",
        "            'article_count': story_info['size'],\n",
        "            'start_date': story_info['start_date'],\n",
        "            'end_date': story_info['end_date']\n",
        "        })\n",
        "\n",
        "    if not lifespans:\n",
        "        return {}\n",
        "\n",
        "    lifespans_df = pd.DataFrame(lifespans)\n",
        "\n",
        "    # Classify stories\n",
        "    duration_q1 = lifespans_df['duration_days'].quantile(0.25)\n",
        "    duration_q3 = lifespans_df['duration_days'].quantile(0.75)\n",
        "\n",
        "    classifications = {}\n",
        "    for _, row in lifespans_df.iterrows():\n",
        "        if row['duration_days'] <= duration_q1:\n",
        "            classification = 'short-lived'\n",
        "        elif row['duration_days'] >= duration_q3:\n",
        "            classification = 'long-running'\n",
        "        else:\n",
        "            classification = 'medium-duration'\n",
        "\n",
        "        classifications[row['story_id']] = {\n",
        "            'classification': classification,\n",
        "            'duration_days': int(row['duration_days']),\n",
        "            'article_count': int(row['article_count']),\n",
        "            'articles_per_day': float(row['article_count'] / max(1, row['duration_days']))\n",
        "        }\n",
        "\n",
        "    # Overall statistics\n",
        "    lifespan_stats = {\n",
        "        'mean_duration': float(lifespans_df['duration_days'].mean()),\n",
        "        'median_duration': float(lifespans_df['duration_days'].median()),\n",
        "        'std_duration': float(lifespans_df['duration_days'].std()),\n",
        "        'min_duration': float(lifespans_df['duration_days'].min()),\n",
        "        'max_duration': float(lifespans_df['duration_days'].max()),\n",
        "        'total_stories': len(lifespans_df),\n",
        "        'classifications': classifications\n",
        "    }\n",
        "\n",
        "    return lifespan_stats"
      ],
      "metadata": {
        "id": "4EOKQ9gMVLd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_coverage_intensity(story_data):\n",
        "    \"\"\"\n",
        "    Analyze volume patterns and peak timing\n",
        "\n",
        "    Args:\n",
        "        story_data: Dict containing story information\n",
        "\n",
        "    Returns:\n",
        "        intensity_analysis: Dict with coverage intensity metrics\n",
        "    \"\"\"\n",
        "    intensity_analysis = {}\n",
        "\n",
        "    for story_id, story_info in story_data.items():\n",
        "        articles = story_info['articles'].sort_values('datetime')\n",
        "\n",
        "        if 'datetime' not in articles.columns:\n",
        "            continue\n",
        "\n",
        "        # Create daily coverage timeline\n",
        "        articles['date_only'] = articles['datetime'].dt.date\n",
        "        daily_counts = articles.groupby('date_only').size()\n",
        "\n",
        "        if len(daily_counts) == 0:\n",
        "            continue\n",
        "\n",
        "        # Find peak\n",
        "        peak_date = daily_counts.idxmax()\n",
        "        peak_count = daily_counts.max()\n",
        "        mean_count = daily_counts.mean()\n",
        "\n",
        "        # Classify peak pattern\n",
        "        if peak_count > mean_count * StoryConfig.PEAK_THRESHOLD_MULTIPLIER:\n",
        "            peak_pattern = 'spike'\n",
        "        else:\n",
        "            peak_pattern = 'sustained'\n",
        "\n",
        "        # Calculate intensity metrics\n",
        "        coverage_start = daily_counts.index.min()\n",
        "        days_to_peak = (peak_date - coverage_start).days if isinstance(peak_date, pd.Timestamp) else 0\n",
        "        total_coverage = daily_counts.sum()\n",
        "\n",
        "        intensity_analysis[story_id] = {\n",
        "            'daily_counts': {str(k): int(v) for k, v in daily_counts.to_dict().items()},\n",
        "            'peak_date': str(peak_date),\n",
        "            'peak_count': int(peak_count),\n",
        "            'mean_daily_count': float(mean_count),\n",
        "            'peak_pattern': peak_pattern,\n",
        "            'days_to_peak': int(days_to_peak),\n",
        "            'total_coverage': int(total_coverage),\n",
        "            'coverage_start': str(coverage_start),\n",
        "            'intensity_score': float(peak_count / max(1, mean_count))\n",
        "        }\n",
        "\n",
        "    return intensity_analysis"
      ],
      "metadata": {
        "id": "hIBfCB0tVevX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_decay_patterns(story_data, intensity_analysis):\n",
        "    \"\"\"\n",
        "    Quantify post-peak decline and decay patterns\n",
        "\n",
        "    Args:\n",
        "        story_data: Dict containing story information\n",
        "        intensity_analysis: Dict from analyze_coverage_intensity\n",
        "\n",
        "    Returns:\n",
        "        decay_analysis: Dict with decay metrics\n",
        "    \"\"\"\n",
        "    decay_analysis = {}\n",
        "\n",
        "    for story_id, story_info in story_data.items():\n",
        "        if story_id not in intensity_analysis:\n",
        "            continue\n",
        "\n",
        "        intensity = intensity_analysis[story_id]\n",
        "\n",
        "        if 'daily_counts' not in intensity or not intensity['daily_counts']:\n",
        "            continue\n",
        "\n",
        "        # Convert daily counts to time series\n",
        "        daily_series = pd.Series(intensity['daily_counts'])\n",
        "        daily_series.index = pd.to_datetime(daily_series.index)\n",
        "        daily_series = daily_series.sort_index()\n",
        "\n",
        "        # Find peak index\n",
        "        if daily_series.empty:\n",
        "            continue\n",
        "\n",
        "        peak_idx = daily_series.idxmax()\n",
        "        post_peak_data = daily_series[daily_series.index > peak_idx]\n",
        "\n",
        "        if len(post_peak_data) < 2:\n",
        "            continue\n",
        "\n",
        "        # Calculate decay metrics\n",
        "        decay_rate = 0\n",
        "        half_life_days = None\n",
        "\n",
        "        if len(post_peak_data) > 1:\n",
        "            # Simple linear decay rate\n",
        "            x = np.arange(len(post_peak_data))\n",
        "            y = post_peak_data.values\n",
        "\n",
        "            if len(y) > 1:\n",
        "                coeffs = np.polyfit(x, y, 1)\n",
        "                decay_rate = abs(coeffs[0])  # Absolute slope\n",
        "\n",
        "                # Estimate half-life (days to reach half of peak)\n",
        "                peak_value = daily_series.max()\n",
        "                half_value = peak_value / 2\n",
        "\n",
        "                for i, val in enumerate(post_peak_data.values):\n",
        "                    if val <= half_value:\n",
        "                        half_life_days = i + 1\n",
        "                        break\n",
        "\n",
        "        # Classify decay pattern\n",
        "        if decay_rate > 0.5:\n",
        "            decay_pattern = 'sharp_decay'\n",
        "        elif decay_rate > 0.1:\n",
        "            decay_pattern = 'gradual_decay'\n",
        "        else:\n",
        "            decay_pattern = 'sustained'\n",
        "\n",
        "        decay_analysis[story_id] = {\n",
        "            'decay_rate': float(decay_rate),\n",
        "            'half_life_days': half_life_days,\n",
        "            'decay_pattern': decay_pattern,\n",
        "            'post_peak_days': len(post_peak_data),\n",
        "            'final_coverage': int(post_peak_data.iloc[-1]) if not post_peak_data.empty else 0,\n",
        "            'peak_to_final_ratio': float(daily_series.max() / max(1, daily_series.iloc[-1]))\n",
        "        }\n",
        "\n",
        "    return decay_analysis"
      ],
      "metadata": {
        "id": "PNedMfOcVlBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_resurgence(story_data, intensity_analysis):\n",
        "    \"\"\"\n",
        "    Detect renewed coverage after inactivity periods\n",
        "\n",
        "    Args:\n",
        "        story_data: Dict containing story information\n",
        "        intensity_analysis: Dict from analyze_coverage_intensity\n",
        "\n",
        "    Returns:\n",
        "        resurgence_analysis: Dict with resurgence detection results\n",
        "    \"\"\"\n",
        "    resurgence_analysis = {}\n",
        "\n",
        "    for story_id, story_info in story_data.items():\n",
        "        if story_id not in intensity_analysis:\n",
        "            continue\n",
        "\n",
        "        intensity = intensity_analysis[story_id]\n",
        "\n",
        "        if 'daily_counts' not in intensity or not intensity['daily_counts']:\n",
        "            continue\n",
        "\n",
        "        # Convert daily counts to time series\n",
        "        daily_series = pd.Series(intensity['daily_counts'])\n",
        "        daily_series.index = pd.to_datetime(daily_series.index)\n",
        "        daily_series = daily_series.sort_index()\n",
        "\n",
        "        if len(daily_series) < 4:  # Need enough data points\n",
        "            continue\n",
        "\n",
        "        # Detect inactivity periods\n",
        "        mean_coverage = daily_series.mean()\n",
        "        inactivity_threshold = mean_coverage * StoryConfig.DECAY_THRESHOLD\n",
        "\n",
        "        inactivity_periods = []\n",
        "        current_period = None\n",
        "\n",
        "        for date, count in daily_series.items():\n",
        "            if count <= inactivity_threshold:\n",
        "                if current_period is None:\n",
        "                    current_period = {'start': date, 'end': date}\n",
        "                else:\n",
        "                    current_period['end'] = date\n",
        "            else:\n",
        "                if current_period is not None:\n",
        "                    duration = (current_period['end'] - current_period['start']).days + 1\n",
        "                    if duration >= StoryConfig.RESURGENCE_WINDOW_DAYS:\n",
        "                        inactivity_periods.append(current_period.copy())\n",
        "                    current_period = None\n",
        "\n",
        "        # Check for final inactivity period\n",
        "        if current_period is not None:\n",
        "            duration = (current_period['end'] - current_period['start']).days + 1\n",
        "            if duration >= StoryConfig.RESURGENCE_WINDOW_DAYS:\n",
        "                inactivity_periods.append(current_period)\n",
        "\n",
        "        # Detect resurgence after inactivity\n",
        "        resurgences = []\n",
        "        for period in inactivity_periods:\n",
        "            # Check period after inactivity\n",
        "            post_inactivity = daily_series[daily_series.index > period['end']]\n",
        "\n",
        "            if not post_inactivity.empty:\n",
        "                # Look for significant increase\n",
        "                for i in range(min(3, len(post_inactivity))):\n",
        "                    if post_inactivity.iloc[i] > inactivity_threshold * 3:  # 3x threshold\n",
        "                        resurgences.append({\n",
        "                            'inactivity_start': str(period['start']),\n",
        "                            'inactivity_end': str(period['end']),\n",
        "                            'inactivity_days': (period['end'] - period['start']).days + 1,\n",
        "                            'resurgence_date': str(post_inactivity.index[i]),\n",
        "                            'resurgence_level': int(post_inactivity.iloc[i])\n",
        "                        })\n",
        "                        break\n",
        "\n",
        "        resurgence_analysis[story_id] = {\n",
        "            'inactivity_periods': [\n",
        "                {\n",
        "                    'start': str(p['start']),\n",
        "                    'end': str(p['end']),\n",
        "                    'days': (p['end'] - p['start']).days + 1\n",
        "                }\n",
        "                for p in inactivity_periods\n",
        "            ],\n",
        "            'resurgence_events': resurgences,\n",
        "            'has_resurgence': len(resurgences) > 0,\n",
        "            'resurgence_count': len(resurgences)\n",
        "        }\n",
        "\n",
        "    return resurgence_analysis"
      ],
      "metadata": {
        "id": "lNlluaFAVtVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualizations**"
      ],
      "metadata": {
        "id": "gDNk0aJ_WHDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Story Evolution Visualizations**"
      ],
      "metadata": {
        "id": "kBYLg4CyWT1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# Visualization Functions\n",
        "# ============================================================================\n",
        "\n",
        "def visualize_story_evolution(story_id, story_info, narrative_evol, sentiment_evol,\n",
        "                            entity_evol, framing_evol, output_dir):\n",
        "    \"\"\"\n",
        "    Create comprehensive visualization for a single story's evolution\n",
        "\n",
        "    Args:\n",
        "        story_id: Story identifier\n",
        "        story_info: Story metadata\n",
        "        narrative_evol: Narrative evolution data\n",
        "        sentiment_evol: Sentiment evolution data\n",
        "        entity_evol: Entity evolution data\n",
        "        framing_evol: Framing evolution data\n",
        "        output_dir: Directory to save visualizations\n",
        "    \"\"\"\n",
        "    if story_id not in narrative_evol:\n",
        "        return\n",
        "\n",
        "    fig, axes = plt.subplots(3, 2, figsize=StoryConfig.FIGURE_SIZE)\n",
        "    fig.suptitle(f'Story Evolution Analysis - Story {story_id}', fontsize=16)\n",
        "\n",
        "    # 1. Narrative keywords over time\n",
        "    if story_id in narrative_evol:\n",
        "        ax = axes[0, 0]\n",
        "        phase_data = narrative_evol[story_id]\n",
        "\n",
        "        for i, keywords in enumerate(phase_data.get('phase_keywords', [])):\n",
        "            y_pos = np.arange(len(keywords))\n",
        "            ax.barh(y_pos + i*0.3, [1]*len(keywords), height=0.25,\n",
        "                   label=f'Phase {i+1}', color=StoryConfig.PLOT_COLORS[i])\n",
        "            for j, kw in enumerate(keywords):\n",
        "                ax.text(0.1, j + i*0.3, kw, va='center', fontsize=8)\n",
        "\n",
        "        ax.set_xlim(0, 1.5)\n",
        "        ax.set_yticks([])\n",
        "        ax.set_xlabel('Phase')\n",
        "        ax.set_title('Dominant Keywords by Phase')\n",
        "        ax.legend()\n",
        "\n",
        "    # 2. Sentiment timeline\n",
        "    if story_id in sentiment_evol:\n",
        "        ax = axes[0, 1]\n",
        "        sentiment_data = sentiment_evol[story_id]['sentiment_timeline']\n",
        "\n",
        "        if sentiment_data:\n",
        "            dates = [pd.Timestamp(item['date']) for item in sentiment_data]\n",
        "            sentiments = [item['sentiment'] for item in sentiment_data]\n",
        "\n",
        "            ax.plot(dates, sentiments, marker='o', color=StoryConfig.PLOT_COLORS[0])\n",
        "            ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
        "            ax.fill_between(dates, sentiments, 0, where=np.array(sentiments) > 0,\n",
        "                           color='green', alpha=0.3)\n",
        "            ax.fill_between(dates, sentiments, 0, where=np.array(sentiments) < 0,\n",
        "                           color='red', alpha=0.3)\n",
        "\n",
        "            ax.set_xlabel('Date')\n",
        "            ax.set_ylabel('Sentiment Score')\n",
        "            ax.set_title('Sentiment Evolution')\n",
        "            ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # 3. Entity emergence\n",
        "    if story_id in entity_evol:\n",
        "        ax = axes[1, 0]\n",
        "        entity_data = entity_evol[story_id]\n",
        "\n",
        "        if 'entity_analysis' in entity_data:\n",
        "            entities = list(entity_data['entity_analysis'].keys())[:10]  # Top 10\n",
        "            patterns = [entity_data['entity_analysis'][e]['pattern'] for e in entities]\n",
        "\n",
        "            # Count by pattern\n",
        "            pattern_counts = pd.Series(patterns).value_counts()\n",
        "            pattern_counts.plot(kind='bar', ax=ax, color=StoryConfig.PLOT_COLORS[:len(pattern_counts)])\n",
        "\n",
        "            ax.set_xlabel('Emergence Pattern')\n",
        "            ax.set_ylabel('Count')\n",
        "            ax.set_title('Entity Emergence Patterns')\n",
        "            ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # 4. Framing evolution\n",
        "    if story_id in framing_evol:\n",
        "        ax = axes[1, 1]\n",
        "        framing_data = framing_evol[story_id]\n",
        "\n",
        "        if 'framing_scores' in framing_data:\n",
        "            for frame_type, scores in framing_data['framing_scores'].items():\n",
        "                ax.plot(range(len(scores)), scores, marker='o', label=frame_type)\n",
        "\n",
        "            ax.set_xlabel('Time Segment')\n",
        "            ax.set_ylabel('Framing Score')\n",
        "            ax.set_title('Framing Evolution')\n",
        "            ax.legend()\n",
        "\n",
        "    # 5. Coverage intensity\n",
        "    ax = axes[2, 0]\n",
        "    if 'articles' in story_info:\n",
        "        articles = story_info['articles'].sort_values('datetime')\n",
        "        daily_counts = articles.groupby(articles['datetime'].dt.date).size()\n",
        "\n",
        "        ax.bar(daily_counts.index, daily_counts.values, color=StoryConfig.PLOT_COLORS[2])\n",
        "        ax.set_xlabel('Date')\n",
        "        ax.set_ylabel('Article Count')\n",
        "        ax.set_title('Daily Coverage Intensity')\n",
        "        ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # 6. Summary metrics\n",
        "    ax = axes[2, 1]\n",
        "    ax.axis('off')\n",
        "\n",
        "    summary_text = f\"\"\"\n",
        "    Story {story_id} Summary:\n",
        "\n",
        "    Duration: {story_info.get('duration_days', 0)} days\n",
        "    Articles: {story_info.get('size', 0)}\n",
        "    Sources: {len(story_info.get('sources', []))}\n",
        "\n",
        "    Sentiment Trend: {sentiment_evol.get(story_id, {}).get('sentiment_trend', 'N/A')}\n",
        "    Polarity Reversal: {sentiment_evol.get(story_id, {}).get('polarity_reversal', False)}\n",
        "\n",
        "    Framing Shifts: {len(framing_evol.get(story_id, {}).get('framing_shifts', []))}\n",
        "    Entity Turnover: {entity_evol.get(story_id, {}).get('entity_turnover', False)}\n",
        "    \"\"\"\n",
        "\n",
        "    ax.text(0.1, 0.5, summary_text, transform=ax.transAxes, fontsize=10,\n",
        "            verticalalignment='center', fontfamily='monospace')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{output_dir}/story_{story_id}_evolution.png\", dpi=300, bbox_inches='tight')\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "K5tUe-l5WFUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_news_cycle_patterns(lifespan_analysis, intensity_analysis,\n",
        "                                 decay_analysis, resurgence_analysis, output_dir):\n",
        "    \"\"\"\n",
        "    Create visualizations for news cycle patterns across all stories\n",
        "\n",
        "    Args:\n",
        "        lifespan_analysis: Lifespan analysis results\n",
        "        intensity_analysis: Intensity analysis results\n",
        "        decay_analysis: Decay analysis results\n",
        "        resurgence_analysis: Resurgence analysis results\n",
        "        output_dir: Directory to save visualizations\n",
        "    \"\"\"\n",
        "    # 1. Lifespan distribution\n",
        "    fig, axes = plt.subplots(2, 2, figsize=StoryConfig.FIGURE_SIZE)\n",
        "\n",
        "    if lifespan_analysis and 'classifications' in lifespan_analysis:\n",
        "        ax = axes[0, 0]\n",
        "        classifications = list(lifespan_analysis['classifications'].values())\n",
        "\n",
        "        if classifications:\n",
        "            durations = [c['duration_days'] for c in classifications]\n",
        "            ax.hist(durations, bins=20, color=StoryConfig.PLOT_COLORS[0], edgecolor='black')\n",
        "            ax.axvline(np.mean(durations), color='red', linestyle='--', label=f'Mean: {np.mean(durations):.1f}')\n",
        "            ax.axvline(np.median(durations), color='green', linestyle='--', label=f'Median: {np.median(durations):.1f}')\n",
        "\n",
        "            ax.set_xlabel('Duration (days)')\n",
        "            ax.set_ylabel('Frequency')\n",
        "            ax.set_title('Story Lifespan Distribution')\n",
        "            ax.legend()\n",
        "\n",
        "    # 2. Intensity vs Duration scatter\n",
        "    if lifespan_analysis and intensity_analysis:\n",
        "        ax = axes[0, 1]\n",
        "\n",
        "        story_ids = list(intensity_analysis.keys())\n",
        "        intensities = [intensity_analysis[sid].get('intensity_score', 0) for sid in story_ids]\n",
        "        durations = [lifespan_analysis['classifications'].get(sid, {}).get('duration_days', 0)\n",
        "                    for sid in story_ids]\n",
        "\n",
        "        ax.scatter(durations, intensities, alpha=0.6, color=StoryConfig.PLOT_COLORS[1])\n",
        "        ax.set_xlabel('Duration (days)')\n",
        "        ax.set_ylabel('Intensity Score')\n",
        "        ax.set_title('Coverage Intensity vs Story Duration')\n",
        "\n",
        "    # 3. Decay patterns\n",
        "    if decay_analysis:\n",
        "        ax = axes[1, 0]\n",
        "\n",
        "        decay_patterns = [d.get('decay_pattern', 'unknown') for d in decay_analysis.values()]\n",
        "        pattern_counts = pd.Series(decay_patterns).value_counts()\n",
        "\n",
        "        pattern_counts.plot(kind='bar', ax=ax, color=StoryConfig.PLOT_COLORS[2])\n",
        "        ax.set_xlabel('Decay Pattern')\n",
        "        ax.set_ylabel('Count')\n",
        "        ax.set_title('Story Decay Patterns')\n",
        "        ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # 4. Resurgence analysis\n",
        "    if resurgence_analysis:\n",
        "        ax = axes[1, 1]\n",
        "\n",
        "        resurgence_counts = [r.get('resurgence_count', 0) for r in resurgence_analysis.values()]\n",
        "\n",
        "        ax.hist(resurgence_counts, bins=range(0, max(resurgence_counts)+2),\n",
        "                color=StoryConfig.PLOT_COLORS[3], edgecolor='black', align='left')\n",
        "        ax.set_xlabel('Number of Resurgence Events')\n",
        "        ax.set_ylabel('Number of Stories')\n",
        "        ax.set_title('Resurgence Event Distribution')\n",
        "\n",
        "    plt.suptitle('News Cycle Pattern Analysis', fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{output_dir}/news_cycle_patterns.png\", dpi=300, bbox_inches='tight')\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "GsJJps0eWRtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# Main Pipeline Functions - Plug n Play Entry Point\n",
        "# ============================================================================\n",
        "\n",
        "def run_story_evolution_pipeline(df, config=StoryConfig):\n",
        "    \"\"\"\n",
        "    Main pipeline function for story evolution tracking and news cycle analysis\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with news articles (must have 'headline', 'description', 'date')\n",
        "        config: Configuration object with parameters\n",
        "\n",
        "    Returns:\n",
        "        results: Dict containing all analysis results\n",
        "    \"\"\"\n",
        "    print(\"=\" * 70)\n",
        "    print(\"STORY EVOLUTION TRACKING & NEWS CYCLE PATTERN ANALYSIS\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    results = {\n",
        "        'config': {k: v for k, v in config.__dict__.items() if not k.startswith('_')},\n",
        "        'timestamp': pd.Timestamp.now().isoformat()\n",
        "    }\n",
        "\n",
        "    # Step 1: Preprocess data for story detection\n",
        "    print(\"\\n[1/6] Preprocessing data for story detection...\")\n",
        "    story_df = preprocess_for_story_detection(df)\n",
        "    print(f\"   Processed {len(story_df)} articles\")\n",
        "\n",
        "    # Step 2: Identify stories\n",
        "    print(\"\\n[2/6] Identifying stories...\")\n",
        "    df_with_stories, story_data = identify_stories(story_df)\n",
        "    results['story_data'] = story_data\n",
        "    print(f\"   Identified {len(story_data)} stories\")\n",
        "\n",
        "    # Step 3: Analyze story evolution\n",
        "    print(\"\\n[3/6] Analyzing story evolution...\")\n",
        "\n",
        "    # Narrative evolution\n",
        "    narrative_evolution = analyze_narrative_evolution(story_data)\n",
        "    results['narrative_evolution'] = narrative_evolution\n",
        "\n",
        "    # Sentiment evolution (using existing sentiment scores)\n",
        "    sentiment_evolution = analyze_sentiment_evolution(story_data)\n",
        "    results['sentiment_evolution'] = sentiment_evolution\n",
        "\n",
        "    # Entity evolution\n",
        "    entity_evolution = extract_entities_from_stories(story_data)\n",
        "    results['entity_evolution'] = entity_evolution\n",
        "\n",
        "    # Framing evolution\n",
        "    framing_evolution = detect_framing_evolution(story_data)\n",
        "    results['framing_evolution'] = framing_evolution\n",
        "\n",
        "    print(f\"   Evolution analysis complete for {len(narrative_evolution)} stories\")\n",
        "\n",
        "    # Step 4: Analyze news cycle patterns\n",
        "    print(\"\\n[4/6] Analyzing news cycle patterns...\")\n",
        "\n",
        "    # Story lifespan\n",
        "    lifespan_analysis = analyze_story_lifespan(story_data)\n",
        "    results['lifespan_analysis'] = lifespan_analysis\n",
        "\n",
        "    # Coverage intensity\n",
        "    intensity_analysis = analyze_coverage_intensity(story_data)\n",
        "    results['intensity_analysis'] = intensity_analysis\n",
        "\n",
        "    # Decay patterns\n",
        "    decay_analysis = analyze_decay_patterns(story_data, intensity_analysis)\n",
        "    results['decay_analysis'] = decay_analysis\n",
        "\n",
        "    # Resurgence detection\n",
        "    resurgence_analysis = detect_resurgence(story_data, intensity_analysis)\n",
        "    results['resurgence_analysis'] = resurgence_analysis\n",
        "\n",
        "    print(f\"   Pattern analysis complete for {len(intensity_analysis)} stories\")\n",
        "\n",
        "    # Step 5: Create visualizations\n",
        "    print(\"\\n[5/6] Creating visualizations...\")\n",
        "\n",
        "    # Visualize each story's evolution\n",
        "    for story_id in list(story_data.keys())[:10]:  # Limit to first 10 for performance\n",
        "        visualize_story_evolution(\n",
        "            story_id, story_data[story_id], narrative_evolution,\n",
        "            sentiment_evolution, entity_evolution, framing_evolution,\n",
        "            config.EVOLUTION_DIR\n",
        "        )\n",
        "\n",
        "    # Visualize overall patterns\n",
        "    visualize_news_cycle_patterns(\n",
        "        lifespan_analysis, intensity_analysis,\n",
        "        decay_analysis, resurgence_analysis,\n",
        "        config.PATTERNS_DIR\n",
        "    )\n",
        "\n",
        "    print(f\"   Visualizations saved to {config.EVOLUTION_DIR} and {config.PATTERNS_DIR}\")\n",
        "\n",
        "    # Step 6: Generate reports\n",
        "    print(\"\\n[6/6] Generating analysis reports...\")\n",
        "\n",
        "    # Save detailed results\n",
        "    import json\n",
        "    def json_serializer(obj):\n",
        "        if isinstance(obj, (pd.Timestamp, pd.Timedelta)):\n",
        "            return str(obj)\n",
        "        if isinstance(obj, np.integer):\n",
        "            return int(obj)\n",
        "        if isinstance(obj, np.floating):\n",
        "            return float(obj)\n",
        "        if isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        raise TypeError(f\"Type {type(obj)} not serializable\")\n",
        "\n",
        "    with open(f\"{config.STORIES_DIR}/story_analysis_results.json\", 'w') as f:\n",
        "        json.dump(results, f, default=json_serializer, indent=2)\n",
        "\n",
        "    # Create summary report\n",
        "    summary_report = {\n",
        "        'total_stories': len(story_data),\n",
        "        'total_articles': len(df_with_stories[df_with_stories['story_id'] != -1]),\n",
        "        'avg_story_duration': lifespan_analysis.get('mean_duration', 0),\n",
        "        'stories_with_sentiment_shifts': sum(1 for se in sentiment_evolution.values()\n",
        "                                           if se.get('positive_shifts', 0) > 0 or\n",
        "                                           se.get('negative_shifts', 0) > 0),\n",
        "        'stories_with_polarity_reversal': sum(1 for se in sentiment_evolution.values()\n",
        "                                            if se.get('polarity_reversal', False)),\n",
        "        'stories_with_resurgence': sum(1 for ra in resurgence_analysis.values()\n",
        "                                      if ra.get('has_resurgence', False)),\n",
        "        'stories_by_lifespan_class': {\n",
        "            'short-lived': sum(1 for c in lifespan_analysis.get('classifications', {}).values()\n",
        "                              if c.get('classification') == 'short-lived'),\n",
        "            'medium-duration': sum(1 for c in lifespan_analysis.get('classifications', {}).values()\n",
        "                                  if c.get('classification') == 'medium-duration'),\n",
        "            'long-running': sum(1 for c in lifespan_analysis.get('classifications', {}).values()\n",
        "                               if c.get('classification') == 'long-running'),\n",
        "        }\n",
        "    }\n",
        "\n",
        "    with open(f\"{config.STORIES_DIR}/summary_report.json\", 'w') as f:\n",
        "        json.dump(summary_report, f, indent=2)\n",
        "\n",
        "    # Save story assignments\n",
        "    df_with_stories.to_csv(f\"{config.STORIES_DIR}/articles_with_stories.csv\", index=False)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"PIPELINE COMPLETED SUCCESSFULLY!\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"\\nResults saved to:\")\n",
        "    print(f\"  {config.STORIES_DIR}/\")\n",
        "    print(f\"    ├── story_analysis_results.json (detailed results)\")\n",
        "    print(f\"    ├── summary_report.json (executive summary)\")\n",
        "    print(f\"    └── articles_with_stories.csv (story assignments)\")\n",
        "    print(f\"  {config.EVOLUTION_DIR}/\")\n",
        "    print(f\"    └── story_*_evolution.png (individual story visualizations)\")\n",
        "    print(f\"  {config.PATTERNS_DIR}/\")\n",
        "    print(f\"    └── news_cycle_patterns.png (overall patterns)\")\n",
        "\n",
        "    print(f\"\\nKey Findings:\")\n",
        "    print(f\"  • Identified {len(story_data)} distinct stories\")\n",
        "    print(f\"  • Average story duration: {summary_report['avg_story_duration']:.1f} days\")\n",
        "    print(f\"  • {summary_report['stories_with_sentiment_shifts']} stories had significant sentiment shifts\")\n",
        "    print(f\"  • {summary_report['stories_with_polarity_reversal']} stories had polarity reversals\")\n",
        "    print(f\"  • {summary_report['stories_with_resurgence']} stories showed resurgence patterns\")\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "nxJrMZyMXwgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# Integration with Training Pipeline\n",
        "# ============================================================================\n",
        "\n",
        "def integrate_with_existing_pipeline():\n",
        "    \"\"\"\n",
        "    Integrate story evolution tracking with existing sentiment analysis pipeline\n",
        "\n",
        "    This function shows how to use the existing combined_df from your pipeline\n",
        "    \"\"\"\n",
        "    # Check if we're in the original pipeline context\n",
        "    try:\n",
        "        # Use the existing combined_df from your code\n",
        "        if 'combined_df' in globals():\n",
        "            print(\"Found existing combined_df. Starting story evolution analysis...\")\n",
        "\n",
        "            # Run the story evolution pipeline\n",
        "            results = run_story_evolution_pipeline(combined_df)\n",
        "\n",
        "            # Add story information to the original dataframe\n",
        "            story_df = preprocess_for_story_detection(combined_df)\n",
        "            df_with_stories, story_data = identify_stories(story_df)\n",
        "\n",
        "            # Merge story IDs back to original dataframe\n",
        "            if 'story_id' in df_with_stories.columns:\n",
        "                combined_df_with_stories = combined_df.copy()\n",
        "                combined_df_with_stories['story_id'] = df_with_stories['story_id']\n",
        "\n",
        "                # Save extended dataset\n",
        "                combined_df_with_stories.to_csv(\n",
        "                    f\"{StoryConfig.STORIES_DIR}/extended_dataset_with_stories.csv\",\n",
        "                    index=False\n",
        "                )\n",
        "\n",
        "                print(\"\\nIntegration complete!\")\n",
        "                print(f\"Extended dataset saved with {len(story_data)} identified stories\")\n",
        "\n",
        "            return results\n",
        "\n",
        "        else:\n",
        "            print(\"Warning: combined_df not found. Please run the original pipeline first.\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Integration error: {str(e)}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "wXN4hJdiZYBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# Usage Example\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\"\n",
        "    Example of how to use this extension:\n",
        "\n",
        "    Option 1: Integrated with existing pipeline (recommended)\n",
        "        results = integrate_with_existing_pipeline()\n",
        "\n",
        "    Option 2: Standalone with custom data\n",
        "        df = pd.read_csv(\"your_data.csv\")\n",
        "        results = run_story_evolution_pipeline(df)\n",
        "    \"\"\"\n",
        "\n",
        "    # Example: Run integrated with existing pipeline\n",
        "    print(\"Starting story evolution tracking extension...\")\n",
        "\n",
        "    # Check if we can integrate\n",
        "    if 'combined_df' in globals():\n",
        "        print(\"Running integrated pipeline...\")\n",
        "        results = integrate_with_existing_pipeline()\n",
        "    else:\n",
        "        print(\"Standalone mode - combined_df not available.\")\n",
        "        print(\"To use this extension, first run the original pipeline to create combined_df\")\n",
        "        print(\"Or load your own DataFrame and call run_story_evolution_pipeline(df)\")"
      ],
      "metadata": {
        "id": "aLK6nLgcZZ5M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}